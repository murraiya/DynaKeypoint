2025-01-24 06:10:32.782 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:10:32.783 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:10:34.003 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (137), thread 'MainThread' (139841964523968):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f2f7dce2e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f2f7e7b6f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f2f7dce2e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f2f7d3e6440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f2f7dd1dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f2f7dd1de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f2f7dd1dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f2f7d242440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f2f7dc6b2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f2f7d46d990>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f2f7dd1cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f2f7d3e63b0>
    │   └ <property object at 0x7f2f7dd4b0b0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f2f7d3e5750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f2f7d3e56c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f2f7e621bd0>

  File "/root/silk/silk/cli/__init__.py", line 67, in _main_dispatch
    module = importlib.import_module(module_name)
             │         │             └ 'silk.cli.training'
             │         └ <function import_module at 0x7f2f7e7b7e20>
             └ <module 'importlib' from '/usr/lib/python3.10/importlib/__init__.py'>

  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.cli.training'
           │          └ <function _gcd_import at 0x7f2f7e8f3400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/cli/training.py", line 7, in <module>
    import pytorch_lightning as pl

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py", line 20, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/__init__.py", line 14, in <module>
    from pytorch_lightning.callbacks.base import Callback
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/base.py", line 26, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/types.py", line 25, in <module>
    from torchmetrics import Metric
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/__init__.py", line 31, in <module>
    import scipy.signal
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/__init__.py", line 320, in <module>
    from ._bsplines import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_bsplines.py", line 7, in <module>
    from ._signaltools import lfilter, sosfilt, lfiltic
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_signaltools.py", line 12, in <module>
    from ._ltisys import dlti
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_ltisys.py", line 29, in <module>
    from scipy.interpolate import make_interp_spline
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/__init__.py", line 167, in <module>
    from ._interpolate import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_interpolate.py", line 14, in <module>
    from . import _fitpack_py
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_py.py", line 8, in <module>
    from ._fitpack_impl import bisplrep, bisplev, dblint  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_impl.py", line 103, in <module>
    'iwrk': array([], dfitpack_int), 'u': array([], float),
            │         │                   └ <built-in function array>
            │         └ <unprintable Int32DType object>
            └ <built-in function array>

TypeError
2025-01-24 06:10:34.015 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 06:14:22.150 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:14:22.151 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:14:23.700 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (335), thread 'MainThread' (139751164531136):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f1a59b6ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f1a5a616f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f1a59b6ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f1a5922e440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f1a59badd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f1a59bade10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f1a59badcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f1a5908a440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f1a59af32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f1a592b9900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f1a59bacee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f1a5922e3b0>
    │   └ <property object at 0x7f1a59bd70b0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f1a5922d750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f1a5922d6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f1a5a47dbd0>

  File "/root/silk/silk/cli/__init__.py", line 67, in _main_dispatch
    module = importlib.import_module(module_name)
             │         │             └ 'silk.cli.training'
             │         └ <function import_module at 0x7f1a5a617e20>
             └ <module 'importlib' from '/usr/lib/python3.10/importlib/__init__.py'>

  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.cli.training'
           │          └ <function _gcd_import at 0x7f1a5a753400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/cli/training.py", line 7, in <module>
    import pytorch_lightning as pl

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py", line 27, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/__init__.py", line 14, in <module>
    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/batch_size_finder.py", line 26, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/callback.py", line 22, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/types.py", line 36, in <module>
    from torchmetrics import Metric
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/__init__.py", line 31, in <module>
    import scipy.signal
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/__init__.py", line 320, in <module>
    from ._bsplines import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_bsplines.py", line 7, in <module>
    from ._signaltools import lfilter, sosfilt, lfiltic
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_signaltools.py", line 12, in <module>
    from ._ltisys import dlti
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_ltisys.py", line 29, in <module>
    from scipy.interpolate import make_interp_spline
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/__init__.py", line 167, in <module>
    from ._interpolate import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_interpolate.py", line 14, in <module>
    from . import _fitpack_py
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_py.py", line 8, in <module>
    from ._fitpack_impl import bisplrep, bisplev, dblint  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_impl.py", line 103, in <module>
    'iwrk': array([], dfitpack_int), 'u': array([], float),
            │         │                   └ <built-in function array>
            │         └ <unprintable Int32DType object>
            └ <built-in function array>

TypeError
2025-01-24 06:14:23.714 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 06:17:27.082 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:17:27.083 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:17:28.634 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (531), thread 'MainThread' (139739106984384):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f178b06ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f178bb1ef80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f178b06ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f178a72e440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f178b0add80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f178b0ade10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f178b0adcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f178a592440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f178aff32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f178a7b5990>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f178b0acee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f178a72e3b0>
    │   └ <property object at 0x7f178b0d71a0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f178a72d750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f178a72d6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f178b989bd0>

  File "/root/silk/silk/cli/__init__.py", line 67, in _main_dispatch
    module = importlib.import_module(module_name)
             │         │             └ 'silk.cli.training'
             │         └ <function import_module at 0x7f178bb1fe20>
             └ <module 'importlib' from '/usr/lib/python3.10/importlib/__init__.py'>

  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.cli.training'
           │          └ <function _gcd_import at 0x7f178bc5b400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/cli/training.py", line 7, in <module>
    import pytorch_lightning as pl

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py", line 27, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/__init__.py", line 14, in <module>
    from pytorch_lightning.callbacks.batch_size_finder import BatchSizeFinder
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/batch_size_finder.py", line 26, in <module>
    from pytorch_lightning.callbacks.callback import Callback
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/callback.py", line 22, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/types.py", line 36, in <module>
    from torchmetrics import Metric
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/__init__.py", line 31, in <module>
    import scipy.signal
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/__init__.py", line 320, in <module>
    from ._bsplines import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_bsplines.py", line 7, in <module>
    from ._signaltools import lfilter, sosfilt, lfiltic
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_signaltools.py", line 12, in <module>
    from ._ltisys import dlti
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_ltisys.py", line 29, in <module>
    from scipy.interpolate import make_interp_spline
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/__init__.py", line 167, in <module>
    from ._interpolate import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_interpolate.py", line 14, in <module>
    from . import _fitpack_py
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_py.py", line 8, in <module>
    from ._fitpack_impl import bisplrep, bisplev, dblint  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_impl.py", line 103, in <module>
    'iwrk': array([], dfitpack_int), 'u': array([], float),
            │         │                   └ <built-in function array>
            │         └ <unprintable Int32DType object>
            └ <built-in function array>

TypeError
2025-01-24 06:17:28.646 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 06:22:38.527 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:22:38.528 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:22:39.633 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (981), thread 'MainThread' (140665911538112):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fef54dcee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fef558cef80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fef54dcee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fef544d2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fef54e0dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fef54e0de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fef54e0dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fef54342440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fef54d572e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fef5455d900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fef54e0cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fef544d23b0>
    │   └ <property object at 0x7fef557fa520>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fef544d1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fef544d16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fef55739bd0>

  File "/root/silk/silk/cli/__init__.py", line 67, in _main_dispatch
    module = importlib.import_module(module_name)
             │         │             └ 'silk.cli.training'
             │         └ <function import_module at 0x7fef558cfe20>
             └ <module 'importlib' from '/usr/lib/python3.10/importlib/__init__.py'>

  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.cli.training'
           │          └ <function _gcd_import at 0x7fef55a0b400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/cli/training.py", line 7, in <module>
    import pytorch_lightning as pl

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py", line 20, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/__init__.py", line 14, in <module>
    from pytorch_lightning.callbacks.base import Callback
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/base.py", line 26, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/types.py", line 25, in <module>
    from torchmetrics import Metric
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/__init__.py", line 31, in <module>
    import scipy.signal
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/__init__.py", line 320, in <module>
    from ._bsplines import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_bsplines.py", line 7, in <module>
    from ._signaltools import lfilter, sosfilt, lfiltic
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_signaltools.py", line 12, in <module>
    from ._ltisys import dlti
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_ltisys.py", line 29, in <module>
    from scipy.interpolate import make_interp_spline
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/__init__.py", line 167, in <module>
    from ._interpolate import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_interpolate.py", line 14, in <module>
    from . import _fitpack_py
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_py.py", line 8, in <module>
    from ._fitpack_impl import bisplrep, bisplev, dblint  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_impl.py", line 103, in <module>
    'iwrk': array([], dfitpack_int), 'u': array([], float),
            │         │                   └ <built-in function array>
            │         └ <unprintable Int32DType object>
            └ <built-in function array>

TypeError
2025-01-24 06:22:39.644 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 06:23:50.036 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:23:50.037 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:23:51.055 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (1177), thread 'MainThread' (140125480178112):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f7180adee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f718154ef80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f7180adee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f7180176440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f7180b19d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f7180b19e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f7180b19cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f717ffd2440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f7180a672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f71801fd960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f7180b18ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f71801763b0>
    │   └ <property object at 0x7f7180b03c40>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f7180175750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f71801756c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f71813b5bd0>

  File "/root/silk/silk/cli/__init__.py", line 67, in _main_dispatch
    module = importlib.import_module(module_name)
             │         │             └ 'silk.cli.training'
             │         └ <function import_module at 0x7f718154fe20>
             └ <module 'importlib' from '/usr/lib/python3.10/importlib/__init__.py'>

  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.cli.training'
           │          └ <function _gcd_import at 0x7f718168b400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/cli/training.py", line 7, in <module>
    import pytorch_lightning as pl

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py", line 20, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/__init__.py", line 14, in <module>
    from pytorch_lightning.callbacks.base import Callback
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/base.py", line 26, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/types.py", line 25, in <module>
    from torchmetrics import Metric
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/__init__.py", line 31, in <module>
    import scipy.signal
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/__init__.py", line 320, in <module>
    from ._bsplines import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_bsplines.py", line 7, in <module>
    from ._signaltools import lfilter, sosfilt, lfiltic
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_signaltools.py", line 12, in <module>
    from ._ltisys import dlti
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/_ltisys.py", line 29, in <module>
    from scipy.interpolate import make_interp_spline
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/__init__.py", line 167, in <module>
    from ._interpolate import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_interpolate.py", line 14, in <module>
    from . import _fitpack_py
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_py.py", line 8, in <module>
    from ._fitpack_impl import bisplrep, bisplev, dblint  # noqa: F401
  File "/usr/local/lib/python3.10/dist-packages/scipy/interpolate/_fitpack_impl.py", line 103, in <module>
    'iwrk': array([], dfitpack_int), 'u': array([], float),
            │         │                   └ <built-in function array>
            │         └ <unprintable Int32DType object>
            └ <built-in function array>

TypeError
2025-01-24 06:23:51.072 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 06:27:51.664 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:27:51.665 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:27:52.658 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (1436), thread 'MainThread' (139988976361920):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f51b8666e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f51b9126f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f51b8666e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f51b7d26440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f51b86a5d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f51b86a5e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f51b86a5cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f51b7dde440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f51b85eb2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f51b7db1870>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f51b86a4ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f51b7d263b0>
    │   └ <property object at 0x7f51b868bdd0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f51b7d25750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f51b7d256c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f51b8f89bd0>

  File "/root/silk/silk/cli/__init__.py", line 67, in _main_dispatch
    module = importlib.import_module(module_name)
             │         │             └ 'silk.cli.training'
             │         └ <function import_module at 0x7f51b9127e20>
             └ <module 'importlib' from '/usr/lib/python3.10/importlib/__init__.py'>

  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.cli.training'
           │          └ <function _gcd_import at 0x7f51b925b400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/cli/training.py", line 7, in <module>
    import pytorch_lightning as pl

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py", line 20, in <module>
    from pytorch_lightning.callbacks import Callback  # noqa: E402
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/__init__.py", line 14, in <module>
    from pytorch_lightning.callbacks.base import Callback
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/base.py", line 26, in <module>
    from pytorch_lightning.utilities.types import STEP_OUTPUT
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/types.py", line 25, in <module>
    from torchmetrics import Metric
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/__init__.py", line 31, in <module>
    import scipy.signal
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/__init__.py", line 307, in <module>
    from . import _sigtools, windows
                  └ <module 'scipy.signal._sigtools' from '/usr/local/lib/python3.10/dist-packages/scipy/signal/_sigtools.cpython-310-x86_64-linu...
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/windows/__init__.py", line 42, in <module>
    from ._windows import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/signal/windows/_windows.py", line 7, in <module>
    from scipy import linalg, special, fft as sp_fft
  File "/usr/local/lib/python3.10/dist-packages/scipy/__init__.py", line 134, in __getattr__
    return _importlib.import_module(f'scipy.{name}')
           │          └ <function import_module at 0x7f51b9127e20>
           └ <module 'importlib' from '/usr/lib/python3.10/importlib/__init__.py'>
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'scipy.linalg'
           │          └ <function _gcd_import at 0x7f51b925b400>
           └ <module '_frozen_importlib' (frozen)>
  File "/usr/local/lib/python3.10/dist-packages/scipy/linalg/__init__.py", line 203, in <module>
    from ._misc import *
  File "/usr/local/lib/python3.10/dist-packages/scipy/linalg/_misc.py", line 3, in <module>
    from .blas import get_blas_funcs
  File "/usr/local/lib/python3.10/dist-packages/scipy/linalg/blas.py", line 213, in <module>
    from scipy.linalg import _fblas

ImportError: numpy._core.multiarray failed to import
2025-01-24 06:27:52.701 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 06:29:19.715 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:29:19.716 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:29:23.446 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 06:29:24.715 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (1639), thread 'MainThread' (140630088053184):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
                  │    └ 'silk'
                  └ <module 'silk.models' from '/root/silk/silk/models/__init__.py'>

AttributeError: module 'silk.models' has no attribute 'silk'


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          │             └ 'silk.models.silk'
          └ <function import_module at 0x7fe6fe4dfe20>
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.models.silk'
           │          └ <function _gcd_import at 0x7fe6fe61b400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/models/silk.py", line 17, in <module>
    from silk.losses.sfmlearner.sfm_loss import ones_like_loss, photometric_reconstruction_loss

  File "/root/silk/silk/losses/sfmlearner/sfm_loss.py", line 7, in <module>
    from silk.losses.info_nce.loss import positions_to_unidirectional_correspondence

  File "/root/silk/silk/losses/info_nce/__init__.py", line 10, in <module>
    import jax

ModuleNotFoundError: No module named 'jax'


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             │       └ 'silk.models.silk.SiLKRandomHomographies'
             └ <function _locate at 0x7fe6fda9a170>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 653, in _locate
    raise ImportError(

ImportError: Error loading 'silk.models.silk.SiLKRandomHomographies':
ModuleNotFoundError("No module named 'jax'")
Are you sure that 'silk' is importable from module 'silk.models'?


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fe6fda5ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fe6fe4def80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fe6fda5ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fe6fd0f2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fe6fda99d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fe6fda99e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fe6fda99cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fe6fd1aa440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fe6fd9e32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fe6fd17d930>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fe6fda98ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fe6fd0f23b0>
    │   └ <property object at 0x7fe6fdac7100>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fe6fd0f1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fe6fd0f16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fe6fe349bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fe6fd1aaa70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 49, in main
    model = instantiate_and_ensure_is_instance(config.mode.model, pl.LightningModule)
            │                                  │                  │  └ <class 'pytorch_lightning.core.lightning.LightningModule'>
            │                                  │                  └ <module 'pytorch_lightning' from '/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py'>
            │                                  └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
            └ <function instantiate_and_ensure_is_instance at 0x7fe6fd0f1d80>

  File "/root/silk/silk/config/core.py", line 164, in instantiate_and_ensure_is_instance
    instance = instantiate(cfg)
               │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function instantiate at 0x7fe6fd0f1e10>

  File "/root/silk/silk/config/core.py", line 173, in instantiate
    return hydra.utils.instantiate(cfg)
           │     │     │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
           │     │     └ <function instantiate at 0x7fe6fda9a560>
           │     └ <module 'hydra.utils' from '/usr/local/lib/python3.10/dist-packages/hydra/utils.py'>
           └ <module 'hydra' from '/usr/local/lib/python3.10/dist-packages/hydra/__init__.py'>

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           └ <function instantiate_node at 0x7fe6fda9a680>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               │               │    │   │     │        └ 'mode.model'
               │               │    │   │     └ <_Keys.TARGET: '_target_'>
               │               │    │   └ <enum '_Keys'>
               │               │    └ <function DictConfig.get at 0x7fe6fdbd4f70>
               │               └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function _resolve_target at 0x7fe6fda9a4d0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
          │                      └ "Error locating target 'silk.models.silk.SiLKRandomHomographies', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nf...
          └ <class 'hydra.errors.InstantiationException'>

hydra.errors.InstantiationException: Error locating target 'silk.models.silk.SiLKRandomHomographies', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: mode.model
2025-01-24 06:29:24.727 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 06:36:51.220 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 06:36:51.221 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 06:36:54.735 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 06:37:53.860 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-24 06:37:53.871 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-24 06:37:53.871 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-01-24 07:31:28.634 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 07:31:28.635 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 07:31:32.363 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 07:31:55.943 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 07:34:46.448 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 07:34:46.448 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 07:34:50.104 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 07:35:13.501 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 07:53:09.155 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 07:53:09.156 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 07:53:12.832 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 07:53:36.281 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (3677), thread 'MainThread' (140417881612736):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fb595266e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fb595d12f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fb595266e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fb5948fa440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fb5952a5d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fb5952a5e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fb5952a5cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fb59477e440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fb5951eb2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fb594981930>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fb5952a4ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fb5948fa3b0>
    │   └ <property object at 0x7fb5952cf060>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fb5948f9750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fb5948f96c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fb595b75bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fb59477ea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 90, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7fb33043ba00>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7fb3410ebdf0>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7fb35a9b79a0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7fb35a9b7880>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7fb35a9d03a0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7fb35a9d05e0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
    │    └ <property object at 0x7fb35a9c52b0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7fb35a9d0670>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7fb341124cd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7fb35a9d0790>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1306, in _run_train
    self._run_sanity_check(self.lightning_module)
    │    │                 │    └ <property object at 0x7fb35a9c5800>
    │    │                 └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
    │    └ <function Trainer._run_sanity_check at 0x7fb35a9d0940>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1370, in _run_sanity_check
    self._evaluation_loop.run()
    │    └ <property object at 0x7fb35a9c6ca0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fb341127610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function EvaluationLoop.advance at 0x7fb35a968d30>
    └ <pytorch_lightning.loops.dataloader.evaluation_loop.EvaluationLoop object at 0x7fb33043a6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 109, in advance
    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)
                 │    │          │   │           │               │               │    └ <property object at 0x7fb35a955300>
                 │    │          │   │           │               │               └ <pytorch_lightning.loops.dataloader.evaluation_loop.EvaluationLoop object at 0x7fb33043a6b0>
                 │    │          │   │           │               └ 2
                 │    │          │   │           └ 0
                 │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7fb3410ea950>
                 │    │          └ <function Loop.run at 0x7fb35aaf6b00>
                 │    └ <pytorch_lightning.loops.epoch.evaluation_epoch_loop.EvaluationEpochLoop object at 0x7fb33043ae60>
                 └ <pytorch_lightning.loops.dataloader.evaluation_loop.EvaluationLoop object at 0x7fb33043a6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7fb3410ea950>, 0, 2, 1)
    │    └ <function EvaluationEpochLoop.advance at 0x7fb35a951e10>
    └ <pytorch_lightning.loops.epoch.evaluation_epoch_loop.EvaluationEpochLoop object at 0x7fb33043ae60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 123, in advance
    output = self._evaluation_step(batch, batch_idx, dataloader_idx)
             │    │                │      │          └ 0
             │    │                │      └ 0
             │    │                └ NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
             │    │                             [255., 255., 255.,  ...,  32.,  30....
             │    └ <function EvaluationEpochLoop._evaluation_step at 0x7fb35a952290>
             └ <pytorch_lightning.loops.epoch.evaluation_epoch_loop.EvaluationEpochLoop object at 0x7fb33043ae60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 215, in _evaluation_step
    output = self.trainer.accelerator.validation_step(step_kwargs)
             │    │                                   └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
             │    │                                                [255., 255.,...
             │    └ <property object at 0x7fb35aaf0450>
             └ <pytorch_lightning.loops.epoch.evaluation_epoch_loop.EvaluationEpochLoop object at 0x7fb33043ae60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 236, in validation_step
    return self.training_type_plugin.validation_step(*step_kwargs.values())
           │    │                    │                │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │                └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │    │                    │                             [255., 255.,...
           │    │                    └ <function DDPPlugin.validation_step at 0x7fb39dba1b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7fb341124cd0>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7fb3411251b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 444, in validation_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │    │                   [255., 255., 255.,  ...,  32.,  30...
           │    └ <property object at 0x7fb39db7f5b0>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7fb341124cd0>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │    │                        [255., 255., 255.,  ...,  32.,  30...
           │    └ <function Module._call_impl at 0x7fb443db4670>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │                          [255., 255., 255.,  ...,  32.,  30...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
         │    │                              [255., 255., 255.,  ...,  32.,  30...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7fb4437f8310>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │                         [255., 255., 255.,  ...,  32.,  30...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │    │                        [255., 255., 255.,  ...,  32.,  30...
           │    └ <function Module._call_impl at 0x7fb443db4670>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │                          [255., 255., 255.,  ...,  32.,  30...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 92, in forward
    output = self.module.validation_step(*inputs, **kwargs)
             │                            │         └ {}
             │                            └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
             │                                         [255., 255., 255.,  ...,  32.,  30...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 357, in validation_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7fb345a7f760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 289, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ False
                                     │    │        └ NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
                                     │    │                     [255., 255., 255.,  ...,  32.,  30....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7fb3410fe110>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
           │    │     │              │    │      │    │                             [255., 255., 255.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7fb3410fe110>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7fb3410fe110>
           │    │     └ <function Flow.flow_from_tape at 0x7fb34b2bda20>
           │    └ <silk.flow.Flow object at 0x7fb3410fe410>
           └ <silk.flow.FixedOutputFlow object at 0x7fb3410fe110>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  35.,  34.,  34.],
    │       │        │    │            │      │                     [255., 255., 255.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.5996, 0.6484, 0.6899,  ..., 0.1148, 0.1140, 0.1137],
    │       │        │    │            │                  [0.5800, 0.6582, 0.7489,...
    │       │        │    │            └ 21
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7fb3410fe290>, <silk.flow._InputExtraction object at 0x7fb3410fe1d0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7fb3410fe410>
    │       └ 21
    └ [None, None, None, None, tensor([[[[0.5996, 0.6484, 0.6899,  ..., 0.1148, 0.1140, 0.1137],
                [0.5800, 0.6582, 0.7489,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7fb595a00590>
           │    │          │         │       └ <BoundArguments (pose=tensor([[ 1.0000e+00,  7.5615e-04,  5.6960e-04, -1.3227e-01],
           │    │          │         │                 [-7.5582e-04,  1.0000e+00, -5.711...
           │    │          │         └ <property object at 0x7fb595a00540>
           │    │          └ <BoundArguments (pose=tensor([[ 1.0000e+00,  7.5615e-04,  5.6960e-04, -1.3227e-01],
           │    │                    [-7.5582e-04,  1.0000e+00, -5.711...
           │    └ <function photometric_reconstruction_loss at 0x7fb345a7ed40>
           └ <silk.flow._FunctionCall object at 0x7fb3410fcfa0>

  File "/root/silk/silk/losses/sfmlearner/sfm_loss.py", line 175, in photometric_reconstruction_loss
    reconstruction_loss, desc_loss = compute_diff(intrinsics, rel_pose[1], logits[1], logits[0], descs[1], descs[0], im_1.clone(), im_0.clone(), depth_map_0, positions.clone(), shape)
                                     │            │           │            │          │          │         │         │    │        │    │        │            │         │        └ torch.Size([1, 370, 1226])
                                     │            │           │            │          │          │         │         │    │        │    │        │            │         └ <method 'clone' of 'torch._C.TensorBase' objects>
                                     │            │           │            │          │          │         │         │    │        │    │        │            └ tensor([[[5.0000e-01, 1.5000e+00, 2.5000e+00,  ..., 1.2235e+03,
                                     │            │           │            │          │          │         │         │    │        │    │        │                        1.2245e+03, 1.2255e+03],
                                     │            │           │            │          │          │         │         │    │        │    │        │                       [5.0000e-01, 5.00...
                                     │            │           │            │          │          │         │         │    │        │    │        └ tensor([[[27.8358, 17.6295, 16.3110,  ..., 41.9006, 55.3021, 44.8442],
                                     │            │           │            │          │          │         │         │    │        │    │                   [19.1979, 17.6817, 17.6107,  ..., 38.0412, 39...
                                     │            │           │            │          │          │         │         │    │        │    └ <method 'clone' of 'torch._C.TensorBase' objects>
                                     │            │           │            │          │          │         │         │    │        └ tensor([[[[0.5996, 0.6484, 0.6899,  ..., 0.1148, 0.1140, 0.1137],
                                     │            │           │            │          │          │         │         │    │                    [0.5800, 0.6582, 0.7489,  ..., 0.1055, 0.1070, 0....
                                     │            │           │            │          │          │         │         │    └ <method 'clone' of 'torch._C.TensorBase' objects>
                                     │            │           │            │          │          │         │         └ tensor([[[[0.2937, 0.2921, 0.2701,  ..., 0.1215, 0.1083, 0.1072],
                                     │            │           │            │          │          │         │                     [0.3074, 0.2963, 0.2609,  ..., 0.1025, 0.1044, 0....
                                     │            │           │            │          │          │         └ tensor([[[[0.0871, 0.0873, 0.0886,  ..., 0.0883, 0.0886, 0.0894],
                                     │            │           │            │          │          │                     [0.0871, 0.0887, 0.0887,  ..., 0.0892, 0.0895, 0....
                                     │            │           │            │          │          └ tensor([[[[0.0871, 0.0873, 0.0886,  ..., 0.0883, 0.0886, 0.0894],
                                     │            │           │            │          │                      [0.0871, 0.0887, 0.0887,  ..., 0.0892, 0.0895, 0....
                                     │            │           │            │          └ tensor([[[[0.7205, 0.7133, 0.7122,  ..., 0.7122, 0.7130, 0.7063],
                                     │            │           │            │                      [0.7208, 0.7140, 0.7154,  ..., 0.7183, 0.7152, 0....
                                     │            │           │            └ tensor([[[[0.7205, 0.7133, 0.7122,  ..., 0.7122, 0.7130, 0.7063],
                                     │            │           │                        [0.7208, 0.7140, 0.7154,  ..., 0.7183, 0.7152, 0....
                                     │            │           └ tensor([[[ 1.0000e+00,  7.3225e-04, -7.8408e-05, -1.1180e-03],
                                     │            │                      [-7.3231e-04,  1.0000e+00, -7.5595e-04, -7.4541e-03],...
                                     │            └ tensor([[707.0912,   0.0000, 601.8873],
                                     │                      [  0.0000, 707.0912, 183.1104],
                                     │                      [  0.0000,   0.0000,   1.0000]], devi...
                                     └ <function compute_diff at 0x7fb345a7edd0>

  File "/root/silk/silk/losses/sfmlearner/sfm_loss.py", line 272, in compute_diff
    photo_loss = abs(score*logits_1).mean()
                     │     └ tensor([[[0.7205, 0.7133, 0.7122,  ..., 0.7122, 0.7130, 0.7063],
                     │                [0.7208, 0.7140, 0.7154,  ..., 0.7183, 0.7152, 0.71...
                     └ tensor([[[[ 0.0000, -0.0021,  0.0003,  ...,  0.0004, -0.0002, -0.0008],
                                 [ 0.0000, -0.0024, -0.0004,  ..., -0.0032, ...

RuntimeError: The size of tensor a (1219) must match the size of tensor b (1226) at non-singleton dimension 3
2025-01-24 07:53:36.804 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:09:20.357 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:09:20.358 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:09:23.960 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:09:35.776 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (5494), thread 'MainThread' (139927878029760):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
           │         │       └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f4144206140>, 'image_aug_transform': Albu(), 'training_random_hom...
           │         └ ()
           └ <class 'silk.models.silk.SiLKRandomHomographies'>

  File "/root/silk/silk/models/silk.py", line 377, in __init__
    SiLKBase.__init__(
    │        └ <function SiLKBase.__init__ at 0x7f412f297130>
    └ <class 'silk.models.silk.SiLKBase'>

  File "/root/silk/silk/models/silk.py", line 90, in __init__
    hist = [torch.histogram(c, bins = bins) for c in param]
            │     │                   │              └ Parameter containing:
            │     │                   │                tensor([[[[ 3.3283e-02, -6.7643e-03,  3.0781e-02],
            │     │                   │                          [ 1.2695e-02,  1.6404e-02, -2.7043e-03],
            │     │                   │                 ...
            │     │                   └ tensor([   0.0000,    1.0010,    2.0020,    3.0030,    4.0040,    5.0050,
            │     │                                6.0060,    7.0070,    8.0080,    9.0090,...
            │     └ <built-in method histogram of type object at 0x7f437be59840>
            └ <module 'torch' from '/usr/local/lib/python3.10/dist-packages/torch/__init__.py'>

  File "/root/silk/silk/models/silk.py", line 90, in <listcomp>
    hist = [torch.histogram(c, bins = bins) for c in param]
            │     │         │         │         └ tensor([[[ 3.3283e-02, -6.7643e-03,  3.0781e-02],
            │     │         │         │                    [ 1.2695e-02,  1.6404e-02, -2.7043e-03],
            │     │         │         │                    [-1.3500e-02,  1...
            │     │         │         └ tensor([   0.0000,    1.0010,    2.0020,    3.0030,    4.0040,    5.0050,
            │     │         │                      6.0060,    7.0070,    8.0080,    9.0090,...
            │     │         └ tensor([[[ 3.3283e-02, -6.7643e-03,  3.0781e-02],
            │     │                    [ 1.2695e-02,  1.6404e-02, -2.7043e-03],
            │     │                    [-1.3500e-02,  1...
            │     └ <built-in method histogram of type object at 0x7f437be59840>
            └ <module 'torch' from '/usr/local/lib/python3.10/dist-packages/torch/__init__.py'>

NotImplementedError: Could not run 'aten::histogram.bins_tensor' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::histogram.bins_tensor' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].

CPU: registered at aten/src/ATen/RegisterCPU.cpp:31357 [kernel]
Meta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]
BackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]
Functionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]
Named: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]
Conjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]
Negative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]
ZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]
AutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
AutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]
Tracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16968 [kernel]
AutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]
AutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]
FuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]
BatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]
FuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]
Batched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]
VmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]
PythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]
PreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]
PythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]



The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f437ea6ae40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f437f536f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f437ea6ae40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f437e12a440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f437eaa9d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f437eaa9e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f437eaa9cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f437dfae440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f437e9ef2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f437e1b58d0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f437eaa8ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f437e12a3b0>
    │   └ <property object at 0x7f437ea8fc40>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f437e129750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f437e1296c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f437f39dbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f437dfaea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 49, in main
    model = instantiate_and_ensure_is_instance(config.mode.model, pl.LightningModule)
            │                                  │                  │  └ <class 'pytorch_lightning.core.lightning.LightningModule'>
            │                                  │                  └ <module 'pytorch_lightning' from '/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py'>
            │                                  └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
            └ <function instantiate_and_ensure_is_instance at 0x7f437e129d80>

  File "/root/silk/silk/config/core.py", line 164, in instantiate_and_ensure_is_instance
    instance = instantiate(cfg)
               │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function instantiate at 0x7f437e129e10>

  File "/root/silk/silk/config/core.py", line 173, in instantiate
    return hydra.utils.instantiate(cfg)
           │     │     │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
           │     │     └ <function instantiate at 0x7f437eaaa560>
           │     └ <module 'hydra.utils' from '/usr/local/lib/python3.10/dist-packages/hydra/utils.py'>
           └ <module 'hydra' from '/usr/local/lib/python3.10/dist-packages/hydra/__init__.py'>

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           └ <function instantiate_node at 0x7f437eaaa680>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
           │            │         │        │     │       └ 'mode.model'
           │            │         │        │     └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f4144206140>, 'image_aug_transform': Albu(), 'training_random_hom...
           │            │         │        └ ()
           │            │         └ False
           │            └ <class 'silk.models.silk.SiLKRandomHomographies'>
           └ <function _call_target at 0x7f437eaaa320>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
          │                      └ 'Error in call to target \'silk.models.silk.SiLKRandomHomographies\':\nNotImplementedError("Could not run \'aten::histogram.b...
          └ <class 'hydra.errors.InstantiationException'>

hydra.errors.InstantiationException: Error in call to target 'silk.models.silk.SiLKRandomHomographies':
NotImplementedError("Could not run 'aten::histogram.bins_tensor' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::histogram.bins_tensor' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31357 [kernel]\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:17339 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:16968 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n")
full_key: mode.model
2025-01-24 08:09:35.887 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:10:24.513 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:10:24.513 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:10:28.051 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:10:58.605 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-24 08:10:58.615 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-24 08:10:58.615 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-01-24 08:13:16.713 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:13:16.714 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:13:20.245 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:13:44.849 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-24 08:13:44.860 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-24 08:13:44.860 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-01-24 08:14:09.226 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:14:09.227 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:14:12.788 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:14:47.183 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-24 08:14:47.196 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-24 08:14:47.196 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-01-24 08:17:54.086 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:17:54.087 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:17:57.635 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:18:09.573 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (14277), thread 'MainThread' (140254331470272):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
           │         │       └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f8d4646a0b0>, 'image_aug_transform': Albu(), 'training_random_hom...
           │         └ ()
           └ <class 'silk.models.silk.SiLKRandomHomographies'>

  File "/root/silk/silk/models/silk.py", line 379, in __init__
    SiLKBase.__init__(
    │        └ <function SiLKBase.__init__ at 0x7f8d2e31f250>
    └ <class 'silk.models.silk.SiLKBase'>

  File "/root/silk/silk/models/silk.py", line 91, in __init__
    print(hist.shape)
          └ [torch.return_types.histogram(
            hist=tensor([140., 151., 220., 238., 246., 261., 209., 201., 149.]),
            bin_edges=tensor([-3.0000...

AttributeError: 'list' object has no attribute 'shape'


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f8f80ce2e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f8f8177af80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f8f80ce2e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f8f8037a440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f8f80d21d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f8f80d21e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f8f80d21cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f8f801fe440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f8f80c6b2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f8f80401960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f8f80d20ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f8f8037a3b0>
    │   └ <property object at 0x7f8f80d4afc0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f8f80379750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f8f803796c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f8f815e5bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f8f801fea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 49, in main
    model = instantiate_and_ensure_is_instance(config.mode.model, pl.LightningModule)
            │                                  │                  │  └ <class 'pytorch_lightning.core.lightning.LightningModule'>
            │                                  │                  └ <module 'pytorch_lightning' from '/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py'>
            │                                  └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
            └ <function instantiate_and_ensure_is_instance at 0x7f8f80379d80>

  File "/root/silk/silk/config/core.py", line 164, in instantiate_and_ensure_is_instance
    instance = instantiate(cfg)
               │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function instantiate at 0x7f8f80379e10>

  File "/root/silk/silk/config/core.py", line 173, in instantiate
    return hydra.utils.instantiate(cfg)
           │     │     │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
           │     │     └ <function instantiate at 0x7f8f80d22560>
           │     └ <module 'hydra.utils' from '/usr/local/lib/python3.10/dist-packages/hydra/utils.py'>
           └ <module 'hydra' from '/usr/local/lib/python3.10/dist-packages/hydra/__init__.py'>

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           └ <function instantiate_node at 0x7f8f80d22680>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
           │            │         │        │     │       └ 'mode.model'
           │            │         │        │     └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f8d4646a0b0>, 'image_aug_transform': Albu(), 'training_random_hom...
           │            │         │        └ ()
           │            │         └ False
           │            └ <class 'silk.models.silk.SiLKRandomHomographies'>
           └ <function _call_target at 0x7f8f80d22320>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
          │                      └ 'Error in call to target \'silk.models.silk.SiLKRandomHomographies\':\nAttributeError("\'list\' object has no attribute \'sha...
          └ <class 'hydra.errors.InstantiationException'>

hydra.errors.InstantiationException: Error in call to target 'silk.models.silk.SiLKRandomHomographies':
AttributeError("'list' object has no attribute 'shape'")
full_key: mode.model
2025-01-24 08:18:09.651 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:18:57.162 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:18:57.163 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:19:00.667 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:19:12.604 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:19:46.424 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:19:46.425 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:19:49.960 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:20:05.616 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:20:17.388 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:20:17.389 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:20:20.920 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:21:00.887 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:21:46.107 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:21:46.108 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:21:49.727 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:22:01.697 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (14925), thread 'MainThread' (140069289202112):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
           │         │       └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f6230e5a410>, 'image_aug_transform': Albu(), 'training_random_hom...
           │         └ ()
           └ <class 'silk.models.silk.SiLKRandomHomographies'>

  File "/root/silk/silk/models/silk.py", line 381, in __init__
    SiLKBase.__init__(
    │        └ <function SiLKBase.__init__ at 0x7f6218d03250>
    └ <class 'silk.models.silk.SiLKBase'>

  File "/root/silk/silk/models/silk.py", line 94, in __init__
    plt.plot(hist.bin_edges[:-1], hist[0].hist, color="r", label="{}".format(name))
    │   │    │    │               │                                          └ 'model.kpt_head.0.weight'
    │   │    │    │               └ torch.return_types.histogram(
    │   │    │    │                 hist=tensor([     0.,      0.,      0.,      0., 294912.,      0.,      0.,      0.,
    │   │    │    │                           ...
    │   │    │    └ <member 'bin_edges' of 'torch.return_types.histogram' objects>
    │   │    └ torch.return_types.histogram(
    │   │      hist=tensor([     0.,      0.,      0.,      0., 294912.,      0.,      0.,      0.,
    │   │                ...
    │   └ <function plot at 0x7f62747965f0>
    └ <module 'matplotlib.pyplot' from '/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py'>

AttributeError: 'Tensor' object has no attribute 'hist'. Did you mean: 'dist'?


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f646b6dee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f646c16af80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f646b6dee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f646ad76440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f646b71dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f646b71de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f646b71dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f646abee440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f646b6672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f646ae05900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f646b71cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f646ad763b0>
    │   └ <property object at 0x7f646b703b00>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f646ad75750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f646ad756c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f646bfd1bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f646abeea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 49, in main
    model = instantiate_and_ensure_is_instance(config.mode.model, pl.LightningModule)
            │                                  │                  │  └ <class 'pytorch_lightning.core.lightning.LightningModule'>
            │                                  │                  └ <module 'pytorch_lightning' from '/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py'>
            │                                  └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
            └ <function instantiate_and_ensure_is_instance at 0x7f646ad75d80>

  File "/root/silk/silk/config/core.py", line 164, in instantiate_and_ensure_is_instance
    instance = instantiate(cfg)
               │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function instantiate at 0x7f646ad75e10>

  File "/root/silk/silk/config/core.py", line 173, in instantiate
    return hydra.utils.instantiate(cfg)
           │     │     │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
           │     │     └ <function instantiate at 0x7f646b71e560>
           │     └ <module 'hydra.utils' from '/usr/local/lib/python3.10/dist-packages/hydra/utils.py'>
           └ <module 'hydra' from '/usr/local/lib/python3.10/dist-packages/hydra/__init__.py'>

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           └ <function instantiate_node at 0x7f646b71e680>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
           │            │         │        │     │       └ 'mode.model'
           │            │         │        │     └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f6230e5a410>, 'image_aug_transform': Albu(), 'training_random_hom...
           │            │         │        └ ()
           │            │         └ False
           │            └ <class 'silk.models.silk.SiLKRandomHomographies'>
           └ <function _call_target at 0x7f646b71e320>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
          │                      └ 'Error in call to target \'silk.models.silk.SiLKRandomHomographies\':\nAttributeError("\'Tensor\' object has no attribute \'h...
          └ <class 'hydra.errors.InstantiationException'>

hydra.errors.InstantiationException: Error in call to target 'silk.models.silk.SiLKRandomHomographies':
AttributeError("'Tensor' object has no attribute 'hist'")
full_key: mode.model
2025-01-24 08:22:01.715 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:22:55.958 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:22:55.959 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:22:59.502 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:23:11.436 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (15087), thread 'MainThread' (139834280022464):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
           │         │       └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f2b794263e0>, 'image_aug_transform': Albu(), 'training_random_hom...
           │         └ ()
           └ <class 'silk.models.silk.SiLKRandomHomographies'>

  File "/root/silk/silk/models/silk.py", line 382, in __init__
    SiLKBase.__init__(
    │        └ <function SiLKBase.__init__ at 0x7f2b61307250>
    └ <class 'silk.models.silk.SiLKBase'>

  File "/root/silk/silk/models/silk.py", line 94, in __init__
    plt.plot(hist.bin_edges[:-1], hist[0].hist, color="r", label="{}".format(name))
    │   │    │    │               │                                          └ 'model.kpt_head.0.weight'
    │   │    │    │               └ torch.return_types.histogram(
    │   │    │    │                 hist=tensor([     0.,      0.,      0.,      0.,      0.,      0.,      0.,      0.,
    │   │    │    │                           ...
    │   │    │    └ <member 'bin_edges' of 'torch.return_types.histogram' objects>
    │   │    └ torch.return_types.histogram(
    │   │      hist=tensor([     0.,      0.,      0.,      0.,      0.,      0.,      0.,      0.,
    │   │                ...
    │   └ <function plot at 0x7f2bbcd8e5f0>
    └ <module 'matplotlib.pyplot' from '/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py'>

AttributeError: 'Tensor' object has no attribute 'hist'. Did you mean: 'dist'?


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f2db3c6ae40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f2db4732f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f2db3c6ae40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f2db332a440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f2db3ca9d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f2db3ca9e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f2db3ca9cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f2db31a2440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f2db3bef2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f2db33b1990>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f2db3ca8ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f2db332a3b0>
    │   └ <property object at 0x7f2db3c8fc40>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f2db3329750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f2db33296c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f2db4599bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f2db31a2a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 49, in main
    model = instantiate_and_ensure_is_instance(config.mode.model, pl.LightningModule)
            │                                  │                  │  └ <class 'pytorch_lightning.core.lightning.LightningModule'>
            │                                  │                  └ <module 'pytorch_lightning' from '/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py'>
            │                                  └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
            └ <function instantiate_and_ensure_is_instance at 0x7f2db3329d80>

  File "/root/silk/silk/config/core.py", line 164, in instantiate_and_ensure_is_instance
    instance = instantiate(cfg)
               │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function instantiate at 0x7f2db3329e10>

  File "/root/silk/silk/config/core.py", line 173, in instantiate
    return hydra.utils.instantiate(cfg)
           │     │     │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
           │     │     └ <function instantiate at 0x7f2db3caa560>
           │     └ <module 'hydra.utils' from '/usr/local/lib/python3.10/dist-packages/hydra/utils.py'>
           └ <module 'hydra' from '/usr/local/lib/python3.10/dist-packages/hydra/__init__.py'>

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           └ <function instantiate_node at 0x7f2db3caa680>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
           │            │         │        │     │       └ 'mode.model'
           │            │         │        │     └ {'optimizer_spec': <silk.config.optimizer.Spec object at 0x7f2b794263e0>, 'image_aug_transform': Albu(), 'training_random_hom...
           │            │         │        └ ()
           │            │         └ False
           │            └ <class 'silk.models.silk.SiLKRandomHomographies'>
           └ <function _call_target at 0x7f2db3caa320>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
          │                      └ 'Error in call to target \'silk.models.silk.SiLKRandomHomographies\':\nAttributeError("\'Tensor\' object has no attribute \'h...
          └ <class 'hydra.errors.InstantiationException'>

hydra.errors.InstantiationException: Error in call to target 'silk.models.silk.SiLKRandomHomographies':
AttributeError("'Tensor' object has no attribute 'hist'")
full_key: mode.model
2025-01-24 08:23:11.455 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:23:54.937 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:23:54.938 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:23:58.481 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:24:10.635 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:25:55.885 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:25:55.886 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:25:57.592 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 08:26:13.861 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 08:26:13.862 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 08:26:17.454 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 08:26:29.531 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 10:29:24.865 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 10:29:24.866 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 10:29:28.408 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 10:29:40.329 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 10:31:35.796 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 10:31:35.796 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 10:31:39.336 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 10:31:51.228 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 10:33:05.238 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 10:33:05.239 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 10:33:08.817 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 10:33:20.738 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 10:33:50.077 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 10:33:50.078 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 10:33:53.646 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 10:34:05.539 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 10:47:07.546 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 10:47:07.547 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 10:47:11.739 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 10:47:23.931 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:24:45.194 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:24:45.194 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:24:48.823 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:25:00.841 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:31:21.232 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:31:21.233 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:31:24.772 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:31:37.144 | WARNING  | silk.cli.training:main:57 - the model's weight are being loaded from checkpoint : /home/data1/suji/DynaKeypoint/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:31:37.144 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (194), thread 'MainThread' (140061208576448):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f6289c6ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f628a722f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f6289c6ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f628932e440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f6289cadd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f6289cade10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f6289cadcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f6289192440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f6289bf32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f62893bd900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f6289cacee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f628932e3b0>
    │   └ <property object at 0x7f628a6c7a10>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f628932d750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f628932d6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f628a58dbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f6289192a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 60, in main
    load_model_from_checkpoint(
    └ <function load_model_from_checkpoint at 0x7f6289192680>

  File "/root/silk/silk/config/model.py", line 26, in load_model_from_checkpoint
    checkpoint = pl_load(checkpoint_path, device)
                 │       │                └ None
                 │       └ '/home/data1/suji/DynaKeypoint/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt'
                 └ <function load at 0x7f6092803e20>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/cloud_io.py", line 37, in load
    with fs.open(path_or_url, "rb") as f:
         │  │    └ '/home/data1/suji/DynaKeypoint/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt'
         │  └ <function AbstractFileSystem.open at 0x7f6092864160>
         └ <fsspec.implementations.local.LocalFileSystem object at 0x7f604f215d50>
  File "/usr/local/lib/python3.10/dist-packages/fsspec/spec.py", line 1293, in open
    f = self._open(
        │    └ <function LocalFileSystem._open at 0x7f609287f010>
        └ <fsspec.implementations.local.LocalFileSystem object at 0x7f604f215d50>
  File "/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py", line 197, in _open
    return LocalFileOpener(path, mode, fs=self, **kwargs)
           │               │     │        │       └ {'autocommit': True, 'cache_options': None}
           │               │     │        └ <fsspec.implementations.local.LocalFileSystem object at 0x7f604f215d50>
           │               │     └ 'rb'
           │               └ '/home/data1/suji/DynaKeypoint/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt'
           └ <class 'fsspec.implementations.local.LocalFileOpener'>
  File "/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py", line 322, in __init__
    self._open()
    │    └ <function LocalFileOpener._open at 0x7f609287f640>
    └ <fsspec.implementations.local.LocalFileOpener object at 0x7f604f215e70>
  File "/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py", line 327, in _open
    self.f = open(self.path, mode=self.mode)
    │    │        │    │          │    └ 'rb'
    │    │        │    │          └ <fsspec.implementations.local.LocalFileOpener object at 0x7f604f215e70>
    │    │        │    └ '/home/data1/suji/DynaKeypoint/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt'
    │    │        └ <fsspec.implementations.local.LocalFileOpener object at 0x7f604f215e70>
    │    └ None
    └ <fsspec.implementations.local.LocalFileOpener object at 0x7f604f215e70>

FileNotFoundError: [Errno 2] No such file or directory: '/home/data1/suji/DynaKeypoint/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt'
2025-01-24 11:31:37.160 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:42:01.861 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:42:01.862 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:42:05.404 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:42:17.233 | WARNING  | silk.cli.training:main:57 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:42:18.726 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (356), thread 'MainThread' (139982885446080):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f504d5d6e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f504e066f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f504d5d6e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f504cc6e440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f504d615d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f504d615e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f504d615cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f504cad2440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f504d55f2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f504ccf98a0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f504d614ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f504cc6e3b0>
    │   └ <property object at 0x7f504d63f100>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f504cc6d750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f504cc6d6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f504dec9bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f504cad2a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 60, in main
    load_model_from_checkpoint(
    └ <function load_model_from_checkpoint at 0x7f504cad2680>

  File "/root/silk/silk/config/model.py", line 55, in load_model_from_checkpoint
    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=strict)
                                    │     │               │                  └ True
                                    │     │               └ OrderedDict([('_mods.model.descriptor_scale_factor', tensor(1., device='cuda:1')), ('_mods.model.model.encoder.patch_encoder....
                                    │     └ <function StateDictRedirect.load_state_dict at 0x7f4dfdbdc0d0>
                                    └ SiLKRandomHomographies(
                                        (model): SJNet(
                                          (model): DepthPro(
                                            (encoder): DepthProEncoder(
                                              (patch_encoder): V...

TypeError: cannot unpack non-iterable NoneType object
2025-01-24 11:42:20.226 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:51:03.113 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:51:03.114 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:51:06.655 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:51:18.470 | WARNING  | silk.cli.training:main:57 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:51:19.249 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (518), thread 'MainThread' (140274298589632):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f9426edee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f942799af80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f9426edee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f94265aa440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f9426f1dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f9426f1de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f9426f1dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f9426422440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f9426e672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f9426635900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f9426f1cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f94265aa3b0>
    │   └ <property object at 0x7f9426f03c40>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f94265a9750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f94265a96c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f9427801bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f9426422a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 61, in main
    load_model_from_checkpoint(
    └ <function load_model_from_checkpoint at 0x7f9426422680>

  File "/root/silk/silk/config/model.py", line 55, in load_model_from_checkpoint
    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=strict)
                                    │     │               │                  └ False
                                    │     │               └ OrderedDict([('_mods.model.descriptor_scale_factor', tensor(1., device='cuda:1')), ('_mods.model.model.encoder.patch_encoder....
                                    │     └ <function StateDictRedirect.load_state_dict at 0x7f91d45200d0>
                                    └ SiLKRandomHomographies(
                                        (model): SJNet(
                                          (model): DepthPro(
                                            (encoder): DepthProEncoder(
                                              (patch_encoder): V...

TypeError: cannot unpack non-iterable NoneType object
2025-01-24 11:51:20.728 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:52:44.370 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:52:44.371 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:52:47.916 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:52:59.704 | WARNING  | silk.cli.training:main:58 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:53:00.382 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (680), thread 'MainThread' (139713396752832):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f118e972e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f118f3eef80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f118e972e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f118e006440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f118e9b1d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f118e9b1e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f118e9b1cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f118de6a440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f118e8f72e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f118e08d900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f118e9b0ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f118e0063b0>
    │   └ <property object at 0x7f118f051d00>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f118e005750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f118e0056c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f118f259bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f118de6aa70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 72, in main
    plt.figure(figsize=(20,5))
    │   └ <module 'matplotlib.figure' from '/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py'>
    └ <module 'matplotlib' from '/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py'>

TypeError: 'module' object is not callable
2025-01-24 11:53:00.389 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:53:51.629 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:53:51.629 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:53:55.180 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:54:06.998 | WARNING  | silk.cli.training:main:58 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:54:09.787 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (842), thread 'MainThread' (140311850590656):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f9ce536ae40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f9ce5e02f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f9ce536ae40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f9ce49fe440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f9ce53a9d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f9ce53a9e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f9ce53a9cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f9ce4876440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f9ce52ef2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f9ce4a85930>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f9ce53a8ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f9ce49fe3b0>
    │   └ <property object at 0x7f9ce5ca7ab0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f9ce49fd750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f9ce49fd6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f9ce5c65bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f9ce4876a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 98, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f9a9f9c9de0>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f9a8054a4a0>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f9aaaa9ba30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9a805950c0>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f9aaaa9b910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9a805950c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9a805950c0>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f9aaaab4430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9a805950c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1184, in _run
    self._pre_dispatch()
    │    └ <function Trainer._pre_dispatch at 0x7f9aaaab44c0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9a805950c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1219, in _pre_dispatch
    self.accelerator.pre_dispatch(self)
    │    │                        └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9a805950c0>
    │    └ <property object at 0x7f9aaaaa9580>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9a805950c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 136, in pre_dispatch
    self.training_type_plugin.pre_dispatch()
    │    │                    └ <function DDPPlugin.pre_dispatch at 0x7f9aedbf1750>
    │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9a805a4970>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f9a805a68c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 394, in pre_dispatch
    self.configure_ddp()
    │    └ <function DDPPlugin.configure_ddp at 0x7f9aedbf1630>
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9a805a4970>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 371, in configure_ddp
    self._model = self._setup_model(LightningDistributedModule(self.model))
    │    │        │    │            │                          │    └ <property object at 0x7f9aedbd7100>
    │    │        │    │            │                          └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9a805a4970>
    │    │        │    │            └ <class 'pytorch_lightning.overrides.distributed.LightningDistributedModule'>
    │    │        │    └ <function DDPPlugin._setup_model at 0x7f9aedbf11b0>
    │    │        └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9a805a4970>
    │    └ SiLKRandomHomographies(
    │        (model): SJNet(
    │          (model): DepthPro(
    │            (encoder): DepthProEncoder(
    │              (patch_encoder): V...
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9a805a4970>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 189, in _setup_model
    return DistributedDataParallel(module=model, device_ids=self.determine_ddp_device_ids(), **self._ddp_kwargs)
           │                              │                 │    │                             │    └ {'find_unused_parameters': True}
           │                              │                 │    │                             └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9a805a4970>
           │                              │                 │    └ <function DDPPlugin.determine_ddp_device_ids at 0x7f9aedbf16c0>
           │                              │                 └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9a805a4970>
           │                              └ LightningDistributedModule(
           │                                  (module): SiLKRandomHomographies(
           │                                    (model): SJNet(
           │                                      (model): DepthPro(
           │                                        (encoder...
           └ <class 'torch.nn.parallel.distributed.DistributedDataParallel'>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 671, in __init__
    self._log_and_throw(
    │    └ <function DistributedDataParallel._log_and_throw at 0x7f9b937dbac0>
    └ DistributedDataParallel()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1040, in _log_and_throw
    raise err_type(err_msg)
          │        └ "DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient."
          └ <class 'RuntimeError'>

RuntimeError: DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient.
2025-01-24 11:54:09.884 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:54:59.294 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:54:59.295 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:55:02.837 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:55:14.666 | WARNING  | silk.cli.training:main:58 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:55:17.380 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (1010), thread 'MainThread' (140333391933888):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fa1e92cee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fa1e9d66f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fa1e92cee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fa1e8966440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fa1e9309d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fa1e9309e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fa1e9309cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fa1e8a1e440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fa1e92572e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fa1e89ed900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fa1e9308ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fa1e89663b0>
    │   └ <property object at 0x7fa1e9337100>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fa1e8965750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fa1e89656c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fa1e9bd1bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fa1e8a1ea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 98, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f9fa374e770>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f9f951f2470>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f9fae9f7a30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9f8506c7c0>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f9fae9f7910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9f8506c7c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9f8506c7c0>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f9faea10430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9f8506c7c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1184, in _run
    self._pre_dispatch()
    │    └ <function Trainer._pre_dispatch at 0x7f9faea104c0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9f8506c7c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1219, in _pre_dispatch
    self.accelerator.pre_dispatch(self)
    │    │                        └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9f8506c7c0>
    │    └ <property object at 0x7f9faea093a0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9f8506c7c0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 136, in pre_dispatch
    self.training_type_plugin.pre_dispatch()
    │    │                    └ <function DDPPlugin.pre_dispatch at 0x7f9ff1b89750>
    │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9f85081b10>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f9f85081840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 394, in pre_dispatch
    self.configure_ddp()
    │    └ <function DDPPlugin.configure_ddp at 0x7f9ff1b89630>
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9f85081b10>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 371, in configure_ddp
    self._model = self._setup_model(LightningDistributedModule(self.model))
    │    │        │    │            │                          │    └ <property object at 0x7f9ff1b6ef20>
    │    │        │    │            │                          └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9f85081b10>
    │    │        │    │            └ <class 'pytorch_lightning.overrides.distributed.LightningDistributedModule'>
    │    │        │    └ <function DDPPlugin._setup_model at 0x7f9ff1b891b0>
    │    │        └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9f85081b10>
    │    └ SiLKRandomHomographies(
    │        (model): SJNet(
    │          (model): DepthPro(
    │            (encoder): DepthProEncoder(
    │              (patch_encoder): V...
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9f85081b10>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 189, in _setup_model
    return DistributedDataParallel(module=model, device_ids=self.determine_ddp_device_ids(), **self._ddp_kwargs)
           │                              │                 │    │                             │    └ {'find_unused_parameters': True}
           │                              │                 │    │                             └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9f85081b10>
           │                              │                 │    └ <function DDPPlugin.determine_ddp_device_ids at 0x7f9ff1b896c0>
           │                              │                 └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9f85081b10>
           │                              └ LightningDistributedModule(
           │                                  (module): SiLKRandomHomographies(
           │                                    (model): SJNet(
           │                                      (model): DepthPro(
           │                                        (encoder...
           └ <class 'torch.nn.parallel.distributed.DistributedDataParallel'>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 671, in __init__
    self._log_and_throw(
    │    └ <function DistributedDataParallel._log_and_throw at 0x7fa0977cfac0>
    └ DistributedDataParallel()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1040, in _log_and_throw
    raise err_type(err_msg)
          │        └ "DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient."
          └ <class 'RuntimeError'>

RuntimeError: DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient.
2025-01-24 11:55:17.476 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:56:34.162 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:56:34.163 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:56:37.714 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:56:49.537 | WARNING  | silk.cli.training:main:58 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:56:52.312 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (1178), thread 'MainThread' (139659020120512):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f04e57cee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f04e6252f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f04e57cee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f04e4e66440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f04e580dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f04e580de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f04e580dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f04e4f1e440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f04e57572e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f04e4eed960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f04e580cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f04e4e663b0>
    │   └ <property object at 0x7f04e5836f70>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f04e4e65750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f04e4e656c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f04e60bdbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f04e4f1ea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 98, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f029fc5a290>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f02916e6440>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f02aaf03a30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0281588280>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f02aaf03910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0281588280>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0281588280>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f02aaf1c430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0281588280>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1184, in _run
    self._pre_dispatch()
    │    └ <function Trainer._pre_dispatch at 0x7f02aaf1c4c0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0281588280>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1219, in _pre_dispatch
    self.accelerator.pre_dispatch(self)
    │    │                        └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0281588280>
    │    └ <property object at 0x7f02aaf10fe0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0281588280>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 136, in pre_dispatch
    self.training_type_plugin.pre_dispatch()
    │    │                    └ <function DDPPlugin.pre_dispatch at 0x7f02ee095750>
    │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f028158baf0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f02815892d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 394, in pre_dispatch
    self.configure_ddp()
    │    └ <function DDPPlugin.configure_ddp at 0x7f02ee095630>
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f028158baf0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 371, in configure_ddp
    self._model = self._setup_model(LightningDistributedModule(self.model))
    │    │        │    │            │                          │    └ <property object at 0x7f02ee07af20>
    │    │        │    │            │                          └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f028158baf0>
    │    │        │    │            └ <class 'pytorch_lightning.overrides.distributed.LightningDistributedModule'>
    │    │        │    └ <function DDPPlugin._setup_model at 0x7f02ee0951b0>
    │    │        └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f028158baf0>
    │    └ SiLKRandomHomographies(
    │        (model): SJNet(
    │          (model): DepthPro(
    │            (encoder): DepthProEncoder(
    │              (patch_encoder): V...
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f028158baf0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 189, in _setup_model
    return DistributedDataParallel(module=model, device_ids=self.determine_ddp_device_ids(), **self._ddp_kwargs)
           │                              │                 │    │                             │    └ {'find_unused_parameters': True}
           │                              │                 │    │                             └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f028158baf0>
           │                              │                 │    └ <function DDPPlugin.determine_ddp_device_ids at 0x7f02ee0956c0>
           │                              │                 └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f028158baf0>
           │                              └ LightningDistributedModule(
           │                                  (module): SiLKRandomHomographies(
           │                                    (model): SJNet(
           │                                      (model): DepthPro(
           │                                        (encoder...
           └ <class 'torch.nn.parallel.distributed.DistributedDataParallel'>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 671, in __init__
    self._log_and_throw(
    │    └ <function DistributedDataParallel._log_and_throw at 0x7f0393bcfac0>
    └ DistributedDataParallel()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1040, in _log_and_throw
    raise err_type(err_msg)
          │        └ "DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient."
          └ <class 'RuntimeError'>

RuntimeError: DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient.
2025-01-24 11:56:52.408 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:57:14.119 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:57:14.119 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:57:17.635 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:57:29.329 | WARNING  | silk.cli.training:main:58 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:57:29.973 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:58:31.159 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:58:31.159 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:58:34.709 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:58:38.641 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 11:58:42.670 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 11:58:42.671 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 11:58:46.240 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 11:58:58.043 | WARNING  | silk.cli.training:main:58 - the model's weight are being loaded from checkpoint : /root/silk/lightning_logs/silkimpl_250106/checkpoints/epoch=13-step=11703.ckpt
please make sure to disable it if that's not the intended behavior (by setting `config.mode.continue_from_checkpoint` to `null`).
2025-01-24 11:59:36.844 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-24 11:59:36.854 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-24 11:59:36.854 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-01-24 12:00:41.916 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 12:00:41.917 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 12:00:45.492 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 12:03:23.190 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-24 12:03:23.202 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-24 12:03:23.202 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-01-24 12:03:27.245 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 12:03:27.246 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 12:03:30.861 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 12:04:30.277 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-24 12:04:30.290 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-24 12:04:30.290 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-01-24 12:05:02.411 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 12:05:02.411 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 12:05:05.960 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-24 12:05:17.846 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (11876), thread 'MainThread' (140469289865664):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fc18d4dee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fc18dfc6f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fc18d4dee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fc18cbe2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fc18d51dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fc18d51de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fc18d51dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fc18ca46440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fc18d4672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fc18cc69960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fc18d51cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fc18cbe23b0>
    │   └ <property object at 0x7fc18d546d90>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fc18cbe1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fc18cbe16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fc18de2dbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fc18ca46a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 81, in main
    plt.plot(hist.bin_edges, hist.hist, color=np.random.rand(3,), label="{}".format(name))
    │   │    │    │          │    │           │  │      │                           └ 'model.model.kpt_head.0.weight'
    │   │    │    │          │    │           │  │      └ <built-in method rand of numpy.random.mtrand.RandomState object at 0x7fc12efcc740>
    │   │    │    │          │    │           │  └ <module 'numpy.random' from '/usr/local/lib/python3.10/dist-packages/numpy/random/__init__.py'>
    │   │    │    │          │    │           └ <module 'numpy' from '/usr/local/lib/python3.10/dist-packages/numpy/__init__.py'>
    │   │    │    │          │    └ <member 'hist' of 'torch.return_types.histogram' objects>
    │   │    │    │          └ torch.return_types.histogram(
    │   │    │    │            hist=tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
    │   │    │    │                    0....
    │   │    │    └ <member 'bin_edges' of 'torch.return_types.histogram' objects>
    │   │    └ torch.return_types.histogram(
    │   │      hist=tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
    │   │              0....
    │   └ <function plot at 0x7fbf96692680>
    └ <module 'matplotlib.pyplot' from '/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py'>

  File "/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py", line 3590, in plot
    return gca().plot(
           └ <function gca at 0x7fbf966908b0>
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
              │    │          │      │          │       └ {'color': array([0.19706441, 0.11432632, 0.96512483]), 'label': 'model.model.kpt_head.0.weight'}
              │    │          │      │          └ None
              │    │          │      └ (tensor([-1.0000, -0.9310, -0.8621, -0.7931, -0.7241, -0.6552, -0.5862, -0.5172,
              │    │          │                -0.4483, -0.3793, -0.3103, -0.2414, ...
              │    │          └ <Axes: >
              │    └ <matplotlib.axes._base._process_plot_var_args object at 0x7fbf393c86d0>
              └ <Axes: >
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
               │    └ <function _process_plot_var_args._plot_args at 0x7fbf969bed40>
               └ <matplotlib.axes._base._process_plot_var_args object at 0x7fbf393c86d0>
  File "/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "

ValueError: x and y must have same first dimension, but have shapes torch.Size([30]) and torch.Size([29])
2025-01-24 12:05:17.871 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-01-24 12:08:12.841 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-01-24 12:08:12.841 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-01-24 12:08:16.345 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-01-27 15:05:34.134 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-01-27 15:05:34.145 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-01-27 15:05:34.146 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-02-05 09:40:39.429 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 09:40:39.430 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 09:40:44.065 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 09:55:07.099 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-02-05 09:55:07.109 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-02-05 09:55:07.109 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-02-05 10:18:34.746 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:18:34.747 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:18:38.535 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:19:41.678 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-02-05 10:19:41.690 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-02-05 10:19:41.690 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-02-05 10:24:58.190 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:24:58.191 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:25:01.718 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:27:38.789 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (4779), thread 'MainThread' (139695370408384):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │                         [ 46.,  46.,  44.,  ...,  11.,  11...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │    │                        [ 46.,  46.,  44.,  ...,  11.,  11...
           │    └ <function Module._call_impl at 0x7f0c0abc8700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │                          [ 46.,  46.,  44.,  ...,  11.,  11...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
             │                                       [ 46.,  46.,  44.,  ...,  11.,  11...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f0b09937880>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
                                     │    │                     [ 46.,  46.,  44.,  ...,  11.,  11....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f0af3f86200>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │    │     │              │    │      │    │                             [ 46.,  46.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f0af3f86200>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f0af3f86200>
           │    │     └ <function Flow.flow_from_tape at 0x7f0b12031a20>
           │    └ <silk.flow.Flow object at 0x7f0af3f86440>
           └ <silk.flow.FixedOutputFlow object at 0x7f0af3f86200>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
    │       │        │    │            │      │                     [ 46.,  46.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1048, 0.1404, 0.2059,  ..., 0.0333, 0.0308, 0.0322],
    │       │        │    │            │                  [0.1203, 0.1175, 0.1360,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f0af3f86320>, <silk.flow._InputExtraction object at 0x7f0af3f86290>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f0af3f86440>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1048, 0.1404, 0.2059,  ..., 0.0333, 0.0308, 0.0322],
                [0.1203, 0.1175, 0.1360,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f0d5c9a4450>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f0d5c9a4400>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f0af3f85ab0>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[42, 45, 44,  ...,  0,  0,  0],
           │    │     │         │                   [34, 34, 32,  ...,  0,  0,  0],
           │    │     │         │                   [23, 25, 28,  ...,  ...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f0b0993ada0>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[42, 45, 44,  ...,  0,  0,  0],
           │    │              │     │                           [34, 34, 32,  ...,  0,  0,  0],
           │    │              │     │                           [23, 25, 28,  ...,  ...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f0b12031a20>
           └ <silk.flow.Flow object at 0x7f0b0993ada0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[42, 45, 44,  ...,  0,  0,  0],
    │       │        │    │            │      │                    [34, 34, 32,  ...,  0,  0,  0],
    │       │        │    │            │      │                    [23, 25, 28,  ...,  ...
    │       │        │    │            │      └ [None, None, None, None, None, tensor([[[[15.7117, 11.8790, 11.6920,  ...,  7.6603,  7.6616,  7.7294],
    │       │        │    │            │                  [12.8214, 12...
    │       │        │    │            └ 10
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f0b085b8ee0>, <silk.flow._InputExtraction object at 0x7f0b085b94b0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f0b0993ada0>
    │       └ 10
    └ [None, None, None, None, None, tensor([[[[15.7117, 11.8790, 11.6920,  ...,  7.6603,  7.6616,  7.7294],
                [12.8214, 12...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f0d5c9a4450>
           │    │          │         │       └ <BoundArguments (prob_map=tensor([[[[0.7449, 0.7556, 0.7571,  ..., 0.7529, 0.7486, 0.7451],
           │    │          │         │                   [0.7455, 0.7578, 0.7609...
           │    │          │         └ <property object at 0x7f0d5c9a4400>
           │    │          └ <BoundArguments (prob_map=tensor([[[[0.7449, 0.7556, 0.7571,  ..., 0.7529, 0.7486, 0.7451],
           │    │                      [0.7455, 0.7578, 0.7609...
           │    └ functools.partial(<function prob_map_to_points_map at 0x7f0b14511d80>, prob_thresh=0.0, nms_dist=0, border_dist=8, top_k=3000)
           └ <silk.flow._FunctionCall object at 0x7f0af3f87520>

  File "/root/silk/silk/backbones/superpoint/utils.py", line 135, in prob_map_to_points_map
    prob_thresh = torch.tensor(prob_thresh, device=prob_map.device)
                  │     │      │                   │        └ <attribute 'device' of 'torch._C.TensorBase' objects>
                  │     │      │                   └ tensor([[[0.7449, 0.7556, 0.7571,  ..., 0.7529, 0.7486, 0.7451],
                  │     │      │                              [0.7455, 0.7578, 0.7609,  ..., 0.7614, 0.7604, 0.74...
                  │     │      └ 0.0
                  │     └ <built-in method tensor of type object at 0x7f0d59659840>
                  └ <module 'torch' from '/usr/local/lib/python3.10/dist-packages/torch/__init__.py'>

KeyboardInterrupt


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f0d5c1dae40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f0d5ccaaf80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f0d5c1dae40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f0d5b8a6440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f0d5c219d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f0d5c219e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f0d5c219cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f0d5b72a440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f0d5c1632e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f0d5b931900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f0d5c218ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f0d5b8a63b0>
    │   └ <property object at 0x7f0d5c1ffb00>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f0d5b8a5750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f0d5b8a56c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f0d5cb11bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f0d5b72aa70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 99, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f0af3f53400>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f0af3e95510>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f0b2195fa30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f0b2195f910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f0b21978430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f0b21978670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
    │    └ <property object at 0x7f0b2196d4e0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f0b21978700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f0af3f6b010>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f0b21978820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f0b2196ef70>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0af3f6a290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f0b21916d40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f0af3f6b640>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f0af3ebf4c0>
    │    │          └ <function Loop.run at 0x7f0b2189eb90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f0af3f68250>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f0af3f6b640>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f0af3ebf4c0>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f0b218fbb50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f0af3f68250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 50
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
                   │    │          │                [ 46.,  46.,  44.,  ...,  11.,  11....
                   │    │          └ <function Loop.run at 0x7f0b2189eb90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f0af3f6bc40>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f0af3f68250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
    │    │                     [ 46.,  46.,  44.,  ...,  11.,  11...
    │    └ <function TrainingBatchLoop.advance at 0x7f0b218f88b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f0af3f6bc40>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 50
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
              │    │              │                [ 46.,  46.,  44.,  ...,  11.,  11....
              │    │              └ <function Loop.run at 0x7f0b2189eb90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0af3f68610>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f0af3f6bc40>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
    │    │                     [ 46.,  46.,  44.,  ...,  11.,  11...
    │    └ <function OptimizerLoop.advance at 0x7f0b218f8160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0af3f68610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f0b218f8280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0af3f68610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
    │    │               │          │        └ 50
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f0b218f8670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0af3f68610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f0b21982320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
    │         └ <function LightningOptimizer.step at 0x7f0b64a6a7a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f0af3f91940 to Trainer at 0x7f0af3f6a290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f0c09ed4790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f0af3f68700>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f0af3f69c00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f0af3fca7a0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f0c0a847eb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f0c0a847e20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f0b218ebbe0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0b08122fb0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
                           │    │                                              [ 46.,  46.,...
                           │    └ <property object at 0x7f0b21898400>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0af3f68610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │    │                    │                           [ 46.,  46.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f0b64af5b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f0af3f6b010>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f0af3f69c00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │    │                   [ 46.,  46.,  44.,  ...,  11.,  11...
           │    └ <property object at 0x7f0b64adb0b0>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f0af3f6b010>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │    │                        [ 46.,  46.,  44.,  ...,  11.,  11...
           │    └ <function Module._call_impl at 0x7f0c0abc8700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │                          [ 46.,  46.,  44.,  ...,  11.,  11...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
         │    │                              [ 46.,  46.,  44.,  ...,  11.,  11...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f0c0a80c3a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 53.,  56.,  49.,  ...,  14.,  14.,  12.],
           │                         [ 46.,  46.,  44.,  ...,  11.,  11...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
    └ <built-in function _error_if_any_worker_fails>

RuntimeError: DataLoader worker (pid 6748) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
2025-02-05 10:27:39.449 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:27:43.435 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:27:43.436 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:27:46.957 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:30:28.209 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (8209), thread 'MainThread' (139922968932800):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │                         [255., 255., 255.,  ...,   8.,   8...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │    │                        [255., 255., 255.,  ...,   8.,   8...
           │    └ <function Module._call_impl at 0x7f4108bb4700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │                          [255., 255., 255.,  ...,   8.,   8...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
             │                                       [255., 255., 255.,  ...,   8.,   8...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f400770b7f0>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
                                     │    │                     [255., 255., 255.,  ...,   8.,   8....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f3ff5efe2f0>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │    │     │              │    │      │    │                             [255., 255., 255.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f3ff5efe2f0>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f3ff5efe2f0>
           │    │     └ <function Flow.flow_from_tape at 0x7f40100fd990>
           │    └ <silk.flow.Flow object at 0x7f3ff5efe4a0>
           └ <silk.flow.FixedOutputFlow object at 0x7f3ff5efe2f0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
    │       │        │    │            │      │                     [255., 255., 255.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[1.0000, 1.0000, 1.0000,  ..., 0.0482, 0.0487, 0.0566],
    │       │        │    │            │                  [1.0000, 1.0000, 1.0000,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f3ff5efe320>, <silk.flow._InputExtraction object at 0x7f3ff5efe290>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f3ff5efe4a0>
    │       └ 9
    └ [None, None, None, None, tensor([[[[1.0000, 1.0000, 1.0000,  ..., 0.0482, 0.0487, 0.0566],
                [1.0000, 1.0000, 1.0000,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f425a8804a0>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f425a880450>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f3ff5efdae0>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[ 70,  68,  77,  ...,   0,   0,   0],
           │    │     │         │                   [ 82,  73,  87,  ...,   1,   0,   1],
           │    │     │         │                   [ 74,  7...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f40077030d0>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[ 70,  68,  77,  ...,   0,   0,   0],
           │    │              │     │                           [ 82,  73,  87,  ...,   1,   0,   1],
           │    │              │     │                           [ 74,  7...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f40100fd990>
           └ <silk.flow.Flow object at 0x7f40077030d0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[ 70,  68,  77,  ...,   0,   0,   0],
    │       │        │    │            │      │                    [ 82,  73,  87,  ...,   1,   0,   1],
    │       │        │    │            │      │                    [ 74,  7...
    │       │        │    │            │      └ [None, None, None, None, None, tensor([[[[1.0000e+04, 1.0801e+03, 4.6575e+02,  ..., 5.0472e+00,
    │       │        │    │            │                   5.0455e+00, 5.1339...
    │       │        │    │            └ 10
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f4006491240>, <silk.flow._InputExtraction object at 0x7f4006491810>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f40077030d0>
    │       └ 10
    └ [None, None, None, None, None, tensor([[[[1.0000e+04, 1.0801e+03, 4.6575e+02,  ..., 5.0472e+00,
                 5.0455e+00, 5.1339...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f425a8804a0>
           │    │          │         │       └ <BoundArguments (prob_map=tensor([[[[0.7340, 0.7357, 0.7358,  ..., 0.7353, 0.7352, 0.7335],
           │    │          │         │                   [0.7338, 0.7356, 0.7358...
           │    │          │         └ <property object at 0x7f425a880450>
           │    │          └ <BoundArguments (prob_map=tensor([[[[0.7340, 0.7357, 0.7358,  ..., 0.7353, 0.7352, 0.7335],
           │    │                      [0.7338, 0.7356, 0.7358...
           │    └ functools.partial(<function prob_map_to_points_map at 0x7f4014211cf0>, prob_thresh=0.0, nms_dist=0, border_dist=8, top_k=3000)
           └ <silk.flow._FunctionCall object at 0x7f3ff5eff520>

  File "/root/silk/silk/backbones/superpoint/utils.py", line 135, in prob_map_to_points_map
    prob_thresh = torch.tensor(prob_thresh, device=prob_map.device)
                  │     │      │                   │        └ <attribute 'device' of 'torch._C.TensorBase' objects>
                  │     │      │                   └ tensor([[[0.7340, 0.7357, 0.7358,  ..., 0.7353, 0.7352, 0.7335],
                  │     │      │                              [0.7338, 0.7356, 0.7358,  ..., 0.7356, 0.7354, 0.73...
                  │     │      └ 0.0
                  │     └ <built-in method tensor of type object at 0x7f4257459840>
                  └ <module 'torch' from '/usr/local/lib/python3.10/dist-packages/torch/__init__.py'>

KeyboardInterrupt


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f425a0cee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f425ab86f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f425a0cee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f425979a440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f425a109d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f425a109e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f425a109cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f42595fe440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f425a0572e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f4259821990>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f425a108ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f425979a3b0>
    │   └ <property object at 0x7f425a137100>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f4259799750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f42597996c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f425a9f1bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f42595fea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 99, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f3ff5f20340>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f3ff5e0e1d0>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f401f81fa30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f401f81f910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f401f838430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f401f838670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
    │    └ <property object at 0x7f401f831490>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f401f838700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f3ff5ece620>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f401f838820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f401f832f20>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f3ff5ecccd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f401f7d6d40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f3ff5ecfca0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f3ff5ee48b0>
    │    │          └ <function Loop.run at 0x7f401f95ab90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f3ff5ecf2e0>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f3ff5ecfca0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f3ff5ee48b0>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f401f7bbb50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f3ff5ecf2e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 51
                   │    │          │   └ NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
                   │    │          │                [255., 255., 255.,  ...,   8.,   8....
                   │    │          └ <function Loop.run at 0x7f401f95ab90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f4005fe24d0>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f3ff5ecf2e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
    │    │                     [255., 255., 255.,  ...,   8.,   8...
    │    └ <function TrainingBatchLoop.advance at 0x7f401f7b88b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f4005fe24d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 51
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
              │    │              │                [255., 255., 255.,  ...,   8.,   8....
              │    │              └ <function Loop.run at 0x7f401f95ab90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f4005fe21d0>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f4005fe24d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
    │    │                     [255., 255., 255.,  ...,   8.,   8...
    │    └ <function OptimizerLoop.advance at 0x7f401f7b8160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f4005fe21d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f401f7b8280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f4005fe21d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
    │    │               │          │        └ 51
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f401f7b8670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f4005fe21d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f401f842320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
    │         └ <function LightningOptimizer.step at 0x7f40629567a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f4005fe6d40 to Trainer at 0x7f3ff5ecccd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f4062a34790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f3ff5ece470>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f3ff5ece7d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f3ff5f6e710>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f4108637eb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f4108637e20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f401f7abbe0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f3ff59fd030>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
                           │    │                                              [255., 255.,...
                           │    └ <property object at 0x7f401f9543b0>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f4005fe21d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │    │                    │                           [255., 255.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f40629e1b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f3ff5ece620>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f3ff5ece7d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │    │                   [255., 255., 255.,  ...,   8.,   8...
           │    └ <property object at 0x7f40629c7150>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f3ff5ece620>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │    │                        [255., 255., 255.,  ...,   8.,   8...
           │    └ <function Module._call_impl at 0x7f4108bb4700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │                          [255., 255., 255.,  ...,   8.,   8...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
         │    │                              [255., 255., 255.,  ...,   8.,   8...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f41085fc3a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[255., 255., 255.,  ...,  11.,  11.,  10.],
           │                         [255., 255., 255.,  ...,   8.,   8...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
    └ <built-in function _error_if_any_worker_fails>

RuntimeError: DataLoader worker (pid 10277) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
2025-02-05 10:30:28.864 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:30:32.407 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:30:32.408 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:30:35.958 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:30:49.593 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (11612), thread 'MainThread' (140207537373632):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f849ba6ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f849c526f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f849ba6ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f849b12e440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f849baadd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f849baade10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f849baadcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f849af9e440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f849b9f32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f849b1b5930>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f849baacee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f849b12e3b0>
    │   └ <property object at 0x7f849ba645e0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f849b12d750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f849b12d6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f849c391bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f849af9ea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 99, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f8255f51d50>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f823787a800>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f82611cbac0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f823784e2f0>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f82611cb9a0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f823784e2f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f823784e2f0>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f82611e44c0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f823784e2f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1184, in _run
    self._pre_dispatch()
    │    └ <function Trainer._pre_dispatch at 0x7f82611e4550>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f823784e2f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1219, in _pre_dispatch
    self.accelerator.pre_dispatch(self)
    │    │                        └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f823784e2f0>
    │    └ <property object at 0x7f82611d9210>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f823784e2f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 136, in pre_dispatch
    self.training_type_plugin.pre_dispatch()
    │    │                    └ <function DDPPlugin.pre_dispatch at 0x7f82a43a17e0>
    │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f823784d2a0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f823784c940>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 394, in pre_dispatch
    self.configure_ddp()
    │    └ <function DDPPlugin.configure_ddp at 0x7f82a43a16c0>
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f823784d2a0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 371, in configure_ddp
    self._model = self._setup_model(LightningDistributedModule(self.model))
    │    │        │    │            │                          │    └ <property object at 0x7f82a438a520>
    │    │        │    │            │                          └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f823784d2a0>
    │    │        │    │            └ <class 'pytorch_lightning.overrides.distributed.LightningDistributedModule'>
    │    │        │    └ <function DDPPlugin._setup_model at 0x7f82a43a1240>
    │    │        └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f823784d2a0>
    │    └ SiLKRandomHomographies(
    │        (model): SJNet(
    │          (model): DepthPro(
    │            (encoder): DepthProEncoder(
    │              (patch_encoder): V...
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f823784d2a0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 189, in _setup_model
    return DistributedDataParallel(module=model, device_ids=self.determine_ddp_device_ids(), **self._ddp_kwargs)
           │                              │                 │    │                             │    └ {'find_unused_parameters': True}
           │                              │                 │    │                             └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f823784d2a0>
           │                              │                 │    └ <function DDPPlugin.determine_ddp_device_ids at 0x7f82a43a1750>
           │                              │                 └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f823784d2a0>
           │                              └ LightningDistributedModule(
           │                                  (module): SiLKRandomHomographies(
           │                                    (model): SJNet(
           │                                      (model): DepthPro(
           │                                        (encoder...
           └ <class 'torch.nn.parallel.distributed.DistributedDataParallel'>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 671, in __init__
    self._log_and_throw(
    │    └ <function DistributedDataParallel._log_and_throw at 0x7f8349fd3b50>
    └ DistributedDataParallel()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1040, in _log_and_throw
    raise err_type(err_msg)
          │        └ "DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient."
          └ <class 'RuntimeError'>

RuntimeError: DistributedDataParallel is not needed when a module doesn't have any parameter that requires a gradient.
2025-02-05 10:30:49.689 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:30:56.720 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:30:56.720 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:31:00.219 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:36:12.714 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-02-05 10:36:12.725 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-02-05 10:36:12.725 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-02-05 10:36:15.768 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:36:15.769 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:36:19.281 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:36:30.847 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (15183), thread 'MainThread' (140434826691008):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fb98726ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fb987d22f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fb98726ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fb98692e440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fb9872add80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fb9872ade10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fb9872adcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fb986792440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fb9871f32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fb9869bd900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fb9872acee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fb98692e3b0>
    │   └ <property object at 0x7fb987cc7a10>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fb98692d750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fb98692d6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fb987b8dbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fb986792a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 76, in main
    if name.split('.')[2]=='head' and name.split('.')[-1]=='weight':
       │    │                         │    └ <method 'split' of 'str' objects>
       │    │                         └ 'model.descriptor_scale_factor'
       │    └ <method 'split' of 'str' objects>
       └ 'model.descriptor_scale_factor'

IndexError: list index out of range
2025-02-05 10:36:30.854 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:38:26.976 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:38:26.977 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:38:30.501 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:38:42.048 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (15345), thread 'MainThread' (139657042997696):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f046f9cee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f04704caf80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f046f9cee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f046f0d2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f046fa0dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f046fa0de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f046fa0dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f046ef42440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f046f9572e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f046f159960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f046fa0cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f046f0d23b0>
    │   └ <property object at 0x7f046fa36f70>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f046f0d1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f046f0d16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f0470335bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f046ef42a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 76, in main
    if name.split('.')[1]=='head' and name.split('.')[-1]=='weight':
       │    │                         │    └ <method 'split' of 'str' objects>
       │    │                         └ 'descriptor_scale_factor'
       │    └ <method 'split' of 'str' objects>
       └ 'descriptor_scale_factor'

IndexError: list index out of range
2025-02-05 10:38:42.055 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:39:44.815 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:39:44.815 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:39:48.315 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:39:59.836 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (15507), thread 'MainThread' (140337118323136):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fa2c7466e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fa2c7f32f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fa2c7466e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fa2c6b26440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fa2c74a5d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fa2c74a5e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fa2c74a5cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fa2c6bde440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fa2c73eb2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fa2c6bad990>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fa2c74a4ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fa2c6b263b0>
    │   └ <property object at 0x7fa2c74cf1f0>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fa2c6b25750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fa2c6b256c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fa2c7d95bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fa2c6bdea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 73, in main
    for name, param in model.model.head.named_parameters():
                       └ SiLKRandomHomographies(
                           (model): SJNet(
                             (model): DepthPro(
                               (encoder): DepthProEncoder(
                                 (patch_encoder): V...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1688, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")

AttributeError: 'SJNet' object has no attribute 'head'
2025-02-05 10:39:59.866 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:40:57.206 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:40:57.207 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:41:00.727 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:41:12.250 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (15669), thread 'MainThread' (140110845804992):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f6e1866ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f6e190e2f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f6e1866ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f6e17d02440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f6e186add80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f6e186ade10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f6e186adcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f6e17b5e440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f6e185f32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f6e17d89960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f6e186acee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f6e17d023b0>
    │   └ <property object at 0x7f6e19087a10>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f6e17d01750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f6e17d016c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f6e18f4dbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f6e17b5ea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 73, in main
    for name, param in model.head.named_parameters():
                       └ SiLKRandomHomographies(
                           (model): SJNet(
                             (model): DepthPro(
                               (encoder): DepthProEncoder(
                                 (patch_encoder): V...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1688, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")

AttributeError: 'SiLKRandomHomographies' object has no attribute 'head'
2025-02-05 10:41:12.280 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:41:42.454 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:41:42.455 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:41:45.957 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:42:10.701 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:42:20.241 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:42:20.242 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:42:23.750 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:42:38.469 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:42:52.520 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:42:52.521 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:42:56.044 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:43:22.441 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (16155), thread 'MainThread' (140151447777728):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f778c75ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f778d1eef80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f778c75ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f778bdf2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f778c799d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f778c799e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f778c799cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f778beaa440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f778c6e32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f778be7d8d0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f778c798ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f778bdf23b0>
    │   └ <property object at 0x7f778c7c6e30>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f778bdf1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f778bdf16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f778d059bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f778beaaa70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 101, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f75386afc10>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f75386614e0>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f7551e7fac0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f7551e7f9a0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f7551e944c0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f7551e94700>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
    │    └ <property object at 0x7f7551e8d170>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f7551e94790>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f753867cac0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f7551e948b0>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f7551e8ec00>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f75282c7a90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f7551e32dd0>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f753867ecb0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f7528203f10>
    │    │          └ <function Loop.run at 0x7f7551fb6c20>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f753867db40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f753867ecb0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f7528203f10>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f7551e17be0>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f753867db40>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7f7551fb6c20>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f753867dfc0>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f753867db40>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7f7551e14940>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f753867dfc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7f7551fb6c20>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f753867dcf0>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f753867dfc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7f7551e141f0>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f753867dcf0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f7551e14310>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f753867dcf0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f7551e14700>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f753867dcf0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f7551e9a3b0>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
    │         └ <function LightningOptimizer.step at 0x7f7594f3e830>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f75386b3510 to Trainer at 0x7f75282c7a90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f7595024820>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f753867f880>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f753867e290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f7538927eb0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f763ac2bf40>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f763ac2beb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f7551e07c70>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f76a8300130>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7f7551fb0220>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f753867dcf0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f7594fd5bd0>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f753867cac0>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f753867e290>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7f7594fbaca0>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f753867cac0>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f763abec430>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f753cdcf910>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f75282c62c0>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f75282c62c0>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f75282c62c0>
           │    │     └ <function Flow.flow_from_tape at 0x7f754260dab0>
           │    └ <silk.flow.Flow object at 0x7f75282c6470>
           └ <silk.flow.FixedOutputFlow object at 0x7f75282c62c0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f75282c62f0>, <silk.flow._InputExtraction object at 0x7f75282c6260>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f75282c6470>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f778cee84a0>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f778cee8450>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f75282c5ab0>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[141, 143, 137,  ...,  77,  70,  65],
           │    │     │         │                   [151, 145, 135,  ...,  80,  74,  54],
           │    │     │         │                   [136, 13...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f753cdd2c50>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[141, 143, 137,  ...,  77,  70,  65],
           │    │              │     │                           [151, 145, 135,  ...,  80,  74,  54],
           │    │              │     │                           [136, 13...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f754260dab0>
           └ <silk.flow.Flow object at 0x7f753cdd2c50>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[141, 143, 137,  ...,  77,  70,  65],
    │       │        │    │            │      │                    [151, 145, 135,  ...,  80,  74,  54],
    │       │        │    │            │      │                    [136, 13...
    │       │        │    │            │      └ [None, None, tensor([[[[ 0.1059,  0.1216,  0.0745,  ..., -0.3961, -0.4510, -0.4902],
    │       │        │    │            │                  [ 0.1843,  0.1373,  0.0588,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f7538afcd90>, <silk.flow._InputExtraction object at 0x7f7538afd360>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f753cdd2c50>
    │       └ 4
    └ [None, None, tensor([[[[ 0.1059,  0.1216,  0.0745,  ..., -0.3961, -0.4510, -0.4902],
                [ 0.1843,  0.1373,  0.0588,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f778cee84a0>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[ 0.1059,  0.1216,  0.0745,  ..., -0.3961, -0.4510, -0.4902],
           │    │          │         │                   [ 0.1843,  0.1373,  0.05...
           │    │          │         └ <property object at 0x7f778cee8450>
           │    │          └ <BoundArguments (x=tensor([[[[ 0.1059,  0.1216,  0.0745,  ..., -0.3961, -0.4510, -0.4902],
           │    │                      [ 0.1843,  0.1373,  0.05...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7f75282c7a30>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[ 0.1059,  0.1170,  0.0971,  ..., -0.4224, -0.4623, -0.4902],
                                                 │    │                   [ 0.1059,  0.1170,  0.0971,  ..., -0.4224, ...
                                                 │    └ <function DepthPro.forward at 0x7f7546857760>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[ 0.1059,  0.1170,  0.0971,  ..., -0.4224, -0.4623, -0.4902],
                │                        [ 0.1059,  0.1170,  0.0971,  ..., -0.4224, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[ 0.1059,  0.1170,  0.0971,  ..., -0.4224, -0.4623, -0.4902],
           │    │                       [ 0.1059,  0.1170,  0.0971,  ..., -0.4224,...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[ 0.1059,  0.1170,  0.0971,  ..., -0.4224, -0.4623, -0.4902],
           │                         [ 0.1059,  0.1170,  0.0971,  ..., -0.4224,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[ 0.1059,  0.1170,  0.0971,  ...,  0.9943,  0.9542,  0.9487],
                          │                              [ 0.1059,  0.1170,  0.0971,  ...,  0.9943, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[ 0.1059,  0.1170,  0.0971,  ...,  0.9943,  0.9542,  0.9487],
           │    │                       [ 0.1059,  0.1170,  0.0971,  ...,  0.9943,...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[ 0.1059,  0.1170,  0.0971,  ...,  0.9943,  0.9542,  0.9487],
           │                         [ 0.1059,  0.1170,  0.0971,  ...,  0.9943,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
        │                      [ 0.0490,  0.0900, -0.0301,  ..., -0.0126, -0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │    │                      [ 0.0490,  0.0900, -0.0301,  ..., -0.0126, -...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │                        [ 0.0490,  0.0900, -0.0301,  ..., -0.0126, -...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1511,  0.1453, -0.1393,  ..., -0.3251,  0.1069,  0.4366],
            │                 [ 0.0233, -0.0791, -0.1080,  ..., -0.0473, -0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1511,  0.1453, -0.1393,  ..., -0.3251,  0.1069,  0.4366],
           │    │                      [ 0.0233, -0.0791, -0.1080,  ..., -0.0473, -...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1511,  0.1453, -0.1393,  ..., -0.3251,  0.1069,  0.4366],
           │                        [ 0.0233, -0.0791, -0.1080,  ..., -0.0473, -...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 0.2109, -0.0065, -0.1549,  ..., -0.4767,  0.1781,  0.3711],
        │   │               │        │        │                     [ 0.1138, -0.1613, -0.0601,  ..., -0.0738, -0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 0.2109, -0.0065, -0.1549,  ..., -0.4767,  0.1781,  0.3711],
                   [ 0.1138, -0.1613, -0.0601,  ..., -0.0738, -0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.7265, -0.0497, -0.4970,  ..., -1.6391,  0.5882,  0.9384],
           │    │                      [ 0.7391, -1.0511, -0.3364,  ..., -0.6116, -...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.7265, -0.0497, -0.4970,  ..., -1.6391,  0.5882,  0.9384],
           │                        [ 0.7391, -1.0511, -0.3364,  ..., -0.6116, -...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 43, in forward
    x = self.act(x)
        │        └ tensor([[[-1.4842, -0.1317, -2.5431,  ..., -2.0863, -2.6303, -0.2612],
        │                   [-1.1006, -0.6659, -1.9261,  ..., -2.7120, -1...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.4842, -0.1317, -2.5431,  ..., -2.0863, -2.6303, -0.2612],
           │    │                      [-1.1006, -0.6659, -1.9261,  ..., -2.7120, -...
           │    └ <function Module._call_impl at 0x7f763b1a8790>
           └ GELU(approximate='none')
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.4842, -0.1317, -2.5431,  ..., -2.0863, -2.6303, -0.2612],
           │                        [-1.1006, -0.6659, -1.9261,  ..., -2.7120, -...
           └ <bound method GELU.forward of GELU(approximate='none')>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 682, in forward
    return F.gelu(input, approximate=self.approximate)
           │ │    │                  │    └ 'none'
           │ │    │                  └ GELU(approximate='none')
           │ │    └ tensor([[[-1.4842, -0.1317, -2.5431,  ..., -2.0863, -2.6303, -0.2612],
           │ │               [-1.1006, -0.6659, -1.9261,  ..., -2.7120, -1...
           │ └ <built-in function gelu>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 632.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 414.25 MiB is free. Process 49732 has 47.11 GiB memory in use. Of the allocated memory 46.09 GiB is allocated by PyTorch, and 352.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 10:43:23.704 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:44:21.692 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:44:21.693 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:44:25.217 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:44:46.448 | SUCCESS  | silk.cli:_main:95 - main dispatch successfully executed
2025-02-05 10:44:46.458 | SUCCESS  | silk.cli:_main:99 - formatter successfully converted output
2025-02-05 10:44:46.458 | SUCCESS  | silk.cli:_main:101 - ran successfully in working directory : .
2025-02-05 10:44:48.354 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:44:48.355 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:44:51.855 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:45:03.432 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 10:46:24.770 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 10:46:24.771 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 10:46:28.269 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 10:46:39.882 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:11:01.795 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:11:01.796 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:11:05.293 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:11:16.848 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:27:56.794 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:27:56.795 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:28:00.311 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:28:22.323 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:35:35.945 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:35:35.946 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:35:39.505 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:36:06.911 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (23677), thread 'MainThread' (140334698582464):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fa2370dee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fa237b86f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fa2370dee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fa2367aa440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fa23711dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fa23711de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fa23711dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fa23660e440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fa2370672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fa236835900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fa23711cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fa2367aa3b0>
    │   └ <property object at 0x7fa237103b00>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fa2367a9750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fa2367a96c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fa2379edbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fa23660ea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f9fe2ffcfd0>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f9fd2f07df0>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f9ffc83ba30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f9ffc83b910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f9ffc854430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f9ffc854670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
    │    └ <property object at 0x7f9ffc8494e0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f9ffc854700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9fd2f428f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f9ffc854820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f9ffc84af70>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9fd2f43d00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f9ffc7eed40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f9fd2f43310>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f9fd2f06e00>
    │    │          └ <function Loop.run at 0x7f9ffc976b90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f9fd2f414b0>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f9fd2f43310>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f9fd2f06e00>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f9ffc7d7b50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f9fd2f414b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7f9ffc976b90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f9fd2f40160>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f9fd2f414b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7f9ffc7d48b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f9fd2f40160>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7f9ffc976b90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9fd2f419f0>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f9fd2f40160>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7f9ffc7d4160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9fd2f419f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f9ffc7d4280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9fd2f419f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f9ffc7d4670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9fd2f419f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f9ffc85a320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
    │         └ <function LightningOptimizer.step at 0x7fa03f9767a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f9fd2ecfb50 to Trainer at 0x7f9fd2f43d00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7fa0e4ce4790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f9fd2f41ab0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f9fd2f40dc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f9fe30252d0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7fa0e5647eb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7fa0e5647e20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f9ffc7c7be0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fa1529de6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7f9ffc9704a0>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9fd2f419f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7fa03fa05b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9fd2f428f0>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f9fd2f40dc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7fa03f9eab10>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9fd2f428f0>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7fa0e56043a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f9fe4723760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f9fd2f262f0>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f9fd2f262f0>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f9fd2f262f0>
           │    │     └ <function Flow.flow_from_tape at 0x7f9fecf1da20>
           │    └ <silk.flow.Flow object at 0x7f9fd2f26440>
           └ <silk.flow.FixedOutputFlow object at 0x7f9fd2f262f0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f9fd2f26320>, <silk.flow._InputExtraction object at 0x7f9fd2f26290>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f9fd2f26440>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7fa237880450>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7fa237880400>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f9fd2f25ab0>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[180, 184, 182,  ..., 118, 124, 111],
           │    │     │         │                   [184, 187, 181,  ..., 111, 114, 110],
           │    │     │         │                   [181, 17...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f9fe475b3a0>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[180, 184, 182,  ..., 118, 124, 111],
           │    │              │     │                           [184, 187, 181,  ..., 111, 114, 110],
           │    │              │     │                           [181, 17...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f9fecf1da20>
           └ <silk.flow.Flow object at 0x7f9fe475b3a0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[180, 184, 182,  ..., 118, 124, 111],
    │       │        │    │            │      │                    [184, 187, 181,  ..., 111, 114, 110],
    │       │        │    │            │      │                    [181, 17...
    │       │        │    │            │      └ [None, None, tensor([[[[ 0.4118,  0.4431,  0.4275,  ..., -0.0745, -0.0275, -0.1294],
    │       │        │    │            │                  [ 0.4431,  0.4667,  0.4196,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f9fe34b0f10>, <silk.flow._InputExtraction object at 0x7f9fe34b14e0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f9fe475b3a0>
    │       └ 4
    └ [None, None, tensor([[[[ 0.4118,  0.4431,  0.4275,  ..., -0.0745, -0.0275, -0.1294],
                [ 0.4431,  0.4667,  0.4196,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7fa237880450>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[ 0.4118,  0.4431,  0.4275,  ..., -0.0745, -0.0275, -0.1294],
           │    │          │         │                   [ 0.4431,  0.4667,  0.41...
           │    │          │         └ <property object at 0x7fa237880400>
           │    │          └ <BoundArguments (x=tensor([[[[ 0.4118,  0.4431,  0.4275,  ..., -0.0745, -0.0275, -0.1294],
           │    │                      [ 0.4431,  0.4667,  0.41...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7f9fd2f27a30>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[ 0.4118,  0.4341,  0.4350,  ..., -0.0519, -0.0568, -0.1294],
                                                 │    │                   [ 0.4118,  0.4341,  0.4350,  ..., -0.0519, ...
                                                 │    └ <function DepthPro.forward at 0x7f9ff11976d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[ 0.4118,  0.4341,  0.4350,  ..., -0.0519, -0.0568, -0.1294],
                │                        [ 0.4118,  0.4341,  0.4350,  ..., -0.0519, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[ 0.4118,  0.4341,  0.4350,  ..., -0.0519, -0.0568, -0.1294],
           │    │                       [ 0.4118,  0.4341,  0.4350,  ..., -0.0519,...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[ 0.4118,  0.4341,  0.4350,  ..., -0.0519, -0.0568, -0.1294],
           │                         [ 0.4118,  0.4341,  0.4350,  ..., -0.0519,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[ 0.4118,  0.4341,  0.4350,  ...,  0.9979,  0.9916,  0.9897],
                          │                              [ 0.4118,  0.4341,  0.4350,  ...,  0.9979, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[ 0.4118,  0.4341,  0.4350,  ...,  0.9979,  0.9916,  0.9897],
           │    │                       [ 0.4118,  0.4341,  0.4350,  ...,  0.9979,...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[ 0.4118,  0.4341,  0.4350,  ...,  0.9979,  0.9916,  0.9897],
           │                         [ 0.4118,  0.4341,  0.4350,  ...,  0.9979,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
        │                      [ 0.0433,  0.0616, -0.0474,  ..., -0.0131, -0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │    │                      [ 0.0433,  0.0616, -0.0474,  ..., -0.0131, -...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │                        [ 0.0433,  0.0616, -0.0474,  ..., -0.0131, -...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1814,  0.1274, -0.1744,  ..., -0.2474,  0.1417,  0.4009],
            │                 [-0.0198, -0.1866, -0.0825,  ...,  0.0586, -0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1814,  0.1274, -0.1744,  ..., -0.2474,  0.1417,  0.4009],
           │    │                      [-0.0198, -0.1866, -0.0825,  ...,  0.0586, -...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1814,  0.1274, -0.1744,  ..., -0.2474,  0.1417,  0.4009],
           │                        [-0.0198, -0.1866, -0.0825,  ...,  0.0586, -...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 0.2518, -0.0700, -0.2112,  ..., -0.4098,  0.2267,  0.3149],
        │   │               │        │        │                     [ 0.0545, -0.2309, -0.0717,  ...,  0.0386, -0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 0.2518, -0.0700, -0.2112,  ..., -0.4098,  0.2267,  0.3149],
                   [ 0.0545, -0.2309, -0.0717,  ...,  0.0386, -0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 8.7881e-01, -2.6254e-01, -6.7526e-01,  ..., -1.4201e+00,
           │    │                        7.6686e-01,  7.8031e-01],
           │    │                      [ 3.0891e-...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 8.7881e-01, -2.6254e-01, -6.7526e-01,  ..., -1.4201e+00,
           │                          7.6686e-01,  7.8031e-01],
           │                        [ 3.0891e-...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 43, in forward
    x = self.act(x)
        │        └ tensor([[[-1.5077, -0.1698, -2.3701,  ..., -2.3928, -2.5675, -0.2428],
        │                   [-0.6620, -0.2584, -1.2077,  ..., -2.1265, -0...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.5077, -0.1698, -2.3701,  ..., -2.3928, -2.5675, -0.2428],
           │    │                      [-0.6620, -0.2584, -1.2077,  ..., -2.1265, -...
           │    └ <function Module._call_impl at 0x7fa0e59c8700>
           └ GELU(approximate='none')
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.5077, -0.1698, -2.3701,  ..., -2.3928, -2.5675, -0.2428],
           │                        [-0.6620, -0.2584, -1.2077,  ..., -2.1265, -...
           └ <bound method GELU.forward of GELU(approximate='none')>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 682, in forward
    return F.gelu(input, approximate=self.approximate)
           │ │    │                  │    └ 'none'
           │ │    │                  └ GELU(approximate='none')
           │ │    └ tensor([[[-1.5077, -0.1698, -2.3701,  ..., -2.3928, -2.5675, -0.2428],
           │ │               [-0.6620, -0.2584, -1.2077,  ..., -2.1265, -0...
           │ └ <built-in function gelu>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 632.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 440.25 MiB is free. Process 58091 has 47.08 GiB memory in use. Of the allocated memory 46.09 GiB is allocated by PyTorch, and 326.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 11:36:08.166 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:37:50.743 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:37:50.744 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:37:54.299 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:38:21.783 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (27141), thread 'MainThread' (140711112733120):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7ff9db15ee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7ff9dbc06f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7ff9db15ee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7ff9da7f2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7ff9db199d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7ff9db199e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7ff9db199cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7ff9da8aa440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7ff9db0e32e0>
            └ <hydra._internal.hydra.Hydra object at 0x7ff9da879900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7ff9db198ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7ff9da7f23b0>
    │   └ <property object at 0x7ff9db1c6e30>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7ff9da7f1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7ff9da7f16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7ff9dba71bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7ff9da8aaa70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7ff774353a00>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7ff787003df0>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7ff7a0877a30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7ff7a0877910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7ff7a0890430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7ff7a0890670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
    │    └ <property object at 0x7ff7a0885490>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7ff7a0890700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7ff787041660>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7ff7a0890820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7ff7a0886f20>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7ff7870430d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7ff7a082ad40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7ff787041fc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7ff787002ad0>
    │    │          └ <function Loop.run at 0x7ff7a09beb90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7ff787043f40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7ff787041fc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7ff787002ad0>,)
    │    └ <function TrainingEpochLoop.advance at 0x7ff7a0813b50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7ff787043f40>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7ff7a09beb90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7ff787041a20>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7ff787043f40>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7ff7a08108b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7ff787041a20>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7ff7a09beb90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7ff787043610>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7ff787041a20>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7ff7a0810160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7ff787043610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7ff7a0810280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7ff787043610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7ff7a0810670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7ff787043610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7ff7a0896320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
    │         └ <function LightningOptimizer.step at 0x7ff7e3a067a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7ff7911c68e0 to Trainer at 0x7ff7870430d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7ff7e3ae8790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7ff787043970>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7ff7870431f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7ff7743613f0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7ff88962feb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7ff88962fe20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7ff7a0803be0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7ff8eef470d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7ff7a09b8310>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7ff787043610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7ff7e3a95b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7ff787041660>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7ff7870431f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7ff7e3a7b3d0>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7ff787041660>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7ff8895ec3a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7ff7910e7880>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7ff78701a320>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7ff78701a320>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7ff78701a320>
           │    │     └ <function Flow.flow_from_tape at 0x7ff7911e1a20>
           │    └ <silk.flow.Flow object at 0x7ff78701a470>
           └ <silk.flow.FixedOutputFlow object at 0x7ff78701a320>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7ff78701a350>, <silk.flow._InputExtraction object at 0x7ff78701a290>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7ff78701a470>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7ff9db9004a0>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7ff9db900450>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7ff787019ae0>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[ 45,  45,  45,  ...,   8,   8,   7],
           │    │     │         │                   [ 44,  44,  44,  ...,   5,   6,   5],
           │    │     │         │                   [ 43,  4...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7ff7910eaef0>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[ 45,  45,  45,  ...,   8,   8,   7],
           │    │              │     │                           [ 44,  44,  44,  ...,   5,   6,   5],
           │    │              │     │                           [ 43,  4...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7ff7911e1a20>
           └ <silk.flow.Flow object at 0x7ff7910eaef0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[ 45,  45,  45,  ...,   8,   8,   7],
    │       │        │    │            │      │                    [ 44,  44,  44,  ...,   5,   6,   5],
    │       │        │    │            │      │                    [ 43,  4...
    │       │        │    │            │      └ [None, None, tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
    │       │        │    │            │                  [-0.6549, -0.6549, -0.6549,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7ff7874d5030>, <silk.flow._InputExtraction object at 0x7ff7874d5600>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7ff7910eaef0>
    │       └ 4
    └ [None, None, tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
                [-0.6549, -0.6549, -0.6549,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7ff9db9004a0>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
           │    │          │         │                   [-0.6549, -0.6549, -0.65...
           │    │          │         └ <property object at 0x7ff9db900450>
           │    │          └ <BoundArguments (x=tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
           │    │                      [-0.6549, -0.6549, -0.65...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7ff78701ba60>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
                                                 │    │                   [-0.6471, -0.6471, -0.6471,  ..., -0.9373, ...
                                                 │    └ <function DepthPro.forward at 0x7ff79522b6d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
                │                        [-0.6471, -0.6471, -0.6471,  ..., -0.9373, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
           │    │                       [-0.6471, -0.6471, -0.6471,  ..., -0.9373,...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
           │                         [-0.6471, -0.6471, -0.6471,  ..., -0.9373,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[-0.6471, -0.6471, -0.6471,  ...,  1.0000,  1.0000,  1.0000],
                          │                              [-0.6471, -0.6471, -0.6471,  ...,  1.0000, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ...,  1.0000,  1.0000,  1.0000],
           │    │                       [-0.6471, -0.6471, -0.6471,  ...,  1.0000,...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ...,  1.0000,  1.0000,  1.0000],
           │                         [-0.6471, -0.6471, -0.6471,  ...,  1.0000,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
        │                      [ 0.0359,  0.0849,  0.0150,  ...,  0.0380,  0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │    │                      [ 0.0359,  0.0849,  0.0150,  ...,  0.0380,  ...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │                        [ 0.0359,  0.0849,  0.0150,  ...,  0.0380,  ...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1400,  0.0346, -0.2510,  ..., -0.2697,  0.1182,  0.2969],
            │                 [-0.0113, -0.1870, -0.0645,  ..., -0.0569, -0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1400,  0.0346, -0.2510,  ..., -0.2697,  0.1182,  0.2969],
           │    │                      [-0.0113, -0.1870, -0.0645,  ..., -0.0569, -...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1400,  0.0346, -0.2510,  ..., -0.2697,  0.1182,  0.2969],
           │                        [-0.0113, -0.1870, -0.0645,  ..., -0.0569, -...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 1.9543e-01, -8.0575e-02, -2.4498e-01,  ..., -3.8212e-01,
        │   │               │        │        │                       1.4641e-01,  2.9856e-01],
        │   │               │        │        │                     [ 8.3934e-0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 1.9543e-01, -8.0575e-02, -2.4498e-01,  ..., -3.8212e-01,
                     1.4641e-01,  2.9856e-01],
                   [ 8.3934e-0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 7.1912e-01, -3.1130e-01, -8.3788e-01,  ..., -1.4083e+00,
           │    │                        5.0998e-01,  7.9439e-01],
           │    │                      [ 5.1606e-...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 7.1912e-01, -3.1130e-01, -8.3788e-01,  ..., -1.4083e+00,
           │                          5.0998e-01,  7.9439e-01],
           │                        [ 5.1606e-...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 43, in forward
    x = self.act(x)
        │        └ tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
        │                   [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -1...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
           │    │                      [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -...
           │    └ <function Module._call_impl at 0x7ff889bac700>
           └ GELU(approximate='none')
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
           │                        [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -...
           └ <bound method GELU.forward of GELU(approximate='none')>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 682, in forward
    return F.gelu(input, approximate=self.approximate)
           │ │    │                  │    └ 'none'
           │ │    │                  └ GELU(approximate='none')
           │ │    └ tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
           │ │               [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -1...
           │ └ <built-in function gelu>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 632.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 544.25 MiB is free. Process 61568 has 46.98 GiB memory in use. Of the allocated memory 46.09 GiB is allocated by PyTorch, and 221.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 11:38:22.976 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:38:59.479 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:38:59.480 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:39:03.029 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:39:29.167 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (30605), thread 'MainThread' (140387012944320):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fae653d6e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fae65e6af80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fae653d6e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fae64a6e440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fae65415d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fae65415e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fae65415cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fae648de440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fae6535f2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fae64af98a0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fae65414ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fae64a6e3b0>
    │   └ <property object at 0x7fae6543f100>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fae64a6d750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fae64a6d6c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fae65ccdbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fae648dea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7fac112cba30>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7fac011c7e20>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7fac2ab17a30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7fac2ab17910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7fac2ab30430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7fac2ab30670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
    │    └ <property object at 0x7fac2ab253a0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7fac2ab30700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7fac01202d70>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7fac2ab30820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7fac2ab26e30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7fac01201690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7fac2aacad40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7fac01202020>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7fac011c6b00>
    │    │          └ <function Loop.run at 0x7fac2aa56b90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7fac01203be0>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7fac01202020>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7fac011c6b00>,)
    │    └ <function TrainingEpochLoop.advance at 0x7fac2aab3b50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7fac01203be0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7fac2aa56b90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7fac01201c90>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7fac01203be0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7fac2aab08b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7fac01201c90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7fac2aa56b90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7fac01201840>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7fac01201c90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7fac2aab0160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7fac01201840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7fac2aab0280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7fac01201840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7fac2aab0670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7fac01201840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7fac2ab36320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
    │         └ <function LightningOptimizer.step at 0x7fac6dc127a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7fac011a8950 to Trainer at 0x7fac01201690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7fac6dcf0790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7fac012024a0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7fac01203760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7fac113192d0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7fad1383beb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7fad1383be20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7fac2aaa3be0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7fac00efe5f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7fac2aa502c0>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7fac01201840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7fac6dca1b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7fac01202d70>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7fac01203760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7fac6dc83650>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7fac01202d70>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7fad137f83a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7fac12b1f760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7fac011da350>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7fac011da350>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7fac011da350>
           │    │     └ <function Flow.flow_from_tape at 0x7fac1b215a20>
           │    └ <silk.flow.Flow object at 0x7fac011da4a0>
           └ <silk.flow.FixedOutputFlow object at 0x7fac011da350>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7fac011da380>, <silk.flow._InputExtraction object at 0x7fac011da2c0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7fac011da4a0>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7fae65b58590>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7fae65b58540>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7fac011d9b10>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[  0,   0,   0,  ...,   0,   0,   0],
           │    │     │         │                   [  0,   0,   0,  ...,   0,   0,   0],
           │    │     │         │                   [  0,   ...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7fac12b4f6a0>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[  0,   0,   0,  ...,   0,   0,   0],
           │    │              │     │                           [  0,   0,   0,  ...,   0,   0,   0],
           │    │              │     │                           [  0,   ...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7fac1b215a20>
           └ <silk.flow.Flow object at 0x7fac12b4f6a0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[  0,   0,   0,  ...,   0,   0,   0],
    │       │        │    │            │      │                    [  0,   0,   0,  ...,   0,   0,   0],
    │       │        │    │            │      │                    [  0,   ...
    │       │        │    │            │      └ [None, None, tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
    │       │        │    │            │                  [-1.0000, -1.0000, -1.0000,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7fac11771090>, <silk.flow._InputExtraction object at 0x7fac11771660>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7fac12b4f6a0>
    │       └ 4
    └ [None, None, tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
                [-1.0000, -1.0000, -1.0000,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7fae65b58590>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │    │          │         │                   [-1.0000, -1.0000, -1.00...
           │    │          │         └ <property object at 0x7fae65b58540>
           │    │          └ <BoundArguments (x=tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │    │                      [-1.0000, -1.0000, -1.00...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7fac011dba90>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
                                                 │    │                   [-1.0000, -1.0000, -1.0000,  ..., -1.0000, ...
                                                 │    └ <function DepthPro.forward at 0x7fac1f48b6d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
                │                        [-1.0000, -1.0000, -1.0000,  ..., -1.0000, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │    │                       [-1.0000, -1.0000, -1.0000,  ..., -1.0000,...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │                         [-1.0000, -1.0000, -1.0000,  ..., -1.0000,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[-1.0000, -1.0000, -1.0000,  ...,  0.7961,  0.7961,  0.7961],
                          │                              [-1.0000, -1.0000, -1.0000,  ...,  0.7961, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ...,  0.7961,  0.7961,  0.7961],
           │    │                       [-1.0000, -1.0000, -1.0000,  ...,  0.7961,...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ...,  0.7961,  0.7961,  0.7961],
           │                         [-1.0000, -1.0000, -1.0000,  ...,  0.7961,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
        │                      [ 0.0314,  0.0929,  0.0355,  ...,  0.0585,  0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │    │                      [ 0.0314,  0.0929,  0.0355,  ...,  0.0585,  ...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │                        [ 0.0314,  0.0929,  0.0355,  ...,  0.0585,  ...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1430,  0.0033, -0.2954,  ..., -0.2369,  0.1054,  0.1956],
            │                 [ 0.0318, -0.1806, -0.0855,  ..., -0.0897, -0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1430,  0.0033, -0.2954,  ..., -0.2369,  0.1054,  0.1956],
           │    │                      [ 0.0318, -0.1806, -0.0855,  ..., -0.0897, -...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1430,  0.0033, -0.2954,  ..., -0.2369,  0.1054,  0.1956],
           │                        [ 0.0318, -0.1806, -0.0855,  ..., -0.0897, -...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 0.2038, -0.1221, -0.3118,  ..., -0.3696,  0.1404,  0.1852],
        │   │               │        │        │                     [ 0.1179, -0.1741, -0.0119,  ..., -0.1322, -0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 0.2038, -0.1221, -0.3118,  ..., -0.3696,  0.1404,  0.1852],
                   [ 0.1179, -0.1741, -0.0119,  ..., -0.1322, -0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.7521, -0.4650, -1.0793,  ..., -1.3706,  0.4847,  0.4714],
           │    │                      [ 0.7538, -1.1450, -0.0447,  ..., -0.9451, -...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.7521, -0.4650, -1.0793,  ..., -1.3706,  0.4847,  0.4714],
           │                        [ 0.7538, -1.1450, -0.0447,  ..., -0.9451, -...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 43, in forward
    x = self.act(x)
        │        └ tensor([[[-1.6882e+00, -1.8358e-01, -2.0481e+00,  ..., -1.4374e+00,
        │                    -2.8221e+00, -1.5713e-01],
        │                   [-8.7904e-0...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.6882e+00, -1.8358e-01, -2.0481e+00,  ..., -1.4374e+00,
           │    │                       -2.8221e+00, -1.5713e-01],
           │    │                      [-8.7904e-...
           │    └ <function Module._call_impl at 0x7fad13db8700>
           └ GELU(approximate='none')
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.6882e+00, -1.8358e-01, -2.0481e+00,  ..., -1.4374e+00,
           │                         -2.8221e+00, -1.5713e-01],
           │                        [-8.7904e-...
           └ <bound method GELU.forward of GELU(approximate='none')>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 682, in forward
    return F.gelu(input, approximate=self.approximate)
           │ │    │                  │    └ 'none'
           │ │    │                  └ GELU(approximate='none')
           │ │    └ tensor([[[-1.6882e+00, -1.8358e-01, -2.0481e+00,  ..., -1.4374e+00,
           │ │                -2.8221e+00, -1.5713e-01],
           │ │               [-8.7904e-0...
           │ └ <built-in function gelu>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 632.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 328.25 MiB is free. Process 65046 has 47.19 GiB memory in use. Of the allocated memory 46.09 GiB is allocated by PyTorch, and 437.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 11:39:30.381 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:43:12.228 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:43:12.228 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:43:15.783 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:43:17.026 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (34005), thread 'MainThread' (140550108611008):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
                  │    └ 'silk'
                  └ <module 'silk.models' from '/root/silk/silk/models/__init__.py'>

AttributeError: module 'silk.models' has no attribute 'silk'


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          │             └ 'silk.models.silk'
          └ <function import_module at 0x7fd45f28be20>
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           │          │           │    │        │        └ 0
           │          │           │    │        └ None
           │          │           │    └ 0
           │          │           └ 'silk.models.silk'
           │          └ <function _gcd_import at 0x7fd45f3c7400>
           └ <module '_frozen_importlib' (frozen)>
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed

  File "/root/silk/silk/models/silk.py", line 18, in <module>
    from silk.losses.sfmlearner.sfm_loss import ones_like_loss, photometric_reconstruction_loss

  File "/root/silk/silk/losses/sfmlearner/sfm_loss.py", line 287
    torch.Size([128, 370, 1226]) torch.Size([1, 370, 1226])
                                 ^^^^^

SyntaxError: invalid syntax


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             │       └ 'silk.models.silk.SiLKRandomHomographies'
             └ <function _locate at 0x7fd45e81e170>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(

ImportError: Error loading 'silk.models.silk.SiLKRandomHomographies':
SyntaxError('invalid syntax', ('/root/silk/silk/losses/sfmlearner/sfm_loss.py', 287, 34, '    torch.Size([128, 370, 1226]) torch.Size([1, 370, 1226])\n', 287, 39))


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7fd45e7dee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7fd45f28af80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7fd45e7dee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7fd45deaa440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7fd45e81dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7fd45e81de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7fd45e81dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7fd45dd0e440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7fd45e7672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7fd45df31960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7fd45e81cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7fd45deaa3b0>
    │   └ <property object at 0x7fd45e847010>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7fd45dea9750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7fd45dea96c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7fd45f0f5bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7fd45dd0ea70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 54, in main
    model = instantiate_and_ensure_is_instance(config.mode.model, pl.LightningModule)
            │                                  │                  │  └ <class 'pytorch_lightning.core.lightning.LightningModule'>
            │                                  │                  └ <module 'pytorch_lightning' from '/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py'>
            │                                  └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
            └ <function instantiate_and_ensure_is_instance at 0x7fd45dea9d80>

  File "/root/silk/silk/config/core.py", line 164, in instantiate_and_ensure_is_instance
    instance = instantiate(cfg)
               │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function instantiate at 0x7fd45dea9e10>

  File "/root/silk/silk/config/core.py", line 173, in instantiate
    return hydra.utils.instantiate(cfg)
           │     │     │           └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
           │     │     └ <function instantiate at 0x7fd45e81e560>
           │     └ <module 'hydra.utils' from '/usr/local/lib/python3.10/dist-packages/hydra/utils.py'>
           └ <module 'hydra' from '/usr/local/lib/python3.10/dist-packages/hydra/__init__.py'>

  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           └ <function instantiate_node at 0x7fd45e81e680>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               │               │    │   │     │        └ 'mode.model'
               │               │    │   │     └ <_Keys.TARGET: '_target_'>
               │               │    │   └ <enum '_Keys'>
               │               │    └ <function DictConfig.get at 0x7fd45e9e4f70>
               │               └ {'optimizer_spec': {'_target_': 'silk.config.optimizer.Spec', 'optimizer_class': 'torch.optim.Adam', 'lr': 2e-05, 'betas': [0...
               └ <function _resolve_target at 0x7fd45e81e4d0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
          │                      └ "Error locating target 'silk.models.silk.SiLKRandomHomographies', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nf...
          └ <class 'hydra.errors.InstantiationException'>

hydra.errors.InstantiationException: Error locating target 'silk.models.silk.SiLKRandomHomographies', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: mode.model
2025-02-05 11:43:17.049 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:44:01.415 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:44:01.416 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:44:04.946 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:44:33.168 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (34133), thread 'MainThread' (139703979237824):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f0f5d3d6e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f0f5deb6f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f0f5d3d6e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f0f5caa2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f0f5d415d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f0f5d415e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f0f5d415cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f0f5c926440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f0f5d35f2e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f0f5cb29960>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f0f5d414ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f0f5caa23b0>
    │   └ <property object at 0x7f0f5d43f100>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f0f5caa1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f0f5caa16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f0f5dd19bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f0f5c926a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f0d09306650>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f0cf920be50>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f0d22b5fa30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f0d22b5f910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f0d22b78430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f0d22b78670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
    │    └ <property object at 0x7f0d22b6d210>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f0d22b78700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f0cf9245690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f0d22b78820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f0d22b6eca0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f0cf9246b60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f0d22b12d40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f0cf9245630>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f0cf920ab60>
    │    │          └ <function Loop.run at 0x7f0d22a9eb90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f0cf9247f10>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f0cf9245630>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f0cf920ab60>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f0d22afbb50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f0cf9247f10>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7f0d22a9eb90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f0cf9245ea0>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f0cf9247f10>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7f0d22af88b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f0cf9245ea0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7f0d22a9eb90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0cf9247e80>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f0cf9245ea0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7f0d22af8160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0cf9247e80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f0d22af8280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0cf9247e80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f0d22af8670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0cf9247e80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f0d22b7e320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
    │         └ <function LightningOptimizer.step at 0x7f0d65c6a7a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f0cf91d0400 to Trainer at 0x7f0cf9246b60>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f0e0b0d4790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f0cf9247970>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f0cf9244a30>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f0d0932d2d0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f0e0ba43eb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f0e0ba43e20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f0d22ae7be0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f0e7627da80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7f0d22a98130>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f0cf9247e80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f0d65cf5b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f0cf9245690>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f0cf9244a30>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7f0d65cdaf20>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f0cf9245690>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f0e0ba003a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f0d0ab37760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f0cf92263b0>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f0cf92263b0>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f0cf92263b0>
           │    │     └ <function Flow.flow_from_tape at 0x7f0d13231a20>
           │    └ <silk.flow.Flow object at 0x7f0cf9226410>
           └ <silk.flow.FixedOutputFlow object at 0x7f0cf92263b0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f0cf92262f0>, <silk.flow._InputExtraction object at 0x7f0cf9226230>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f0cf9226410>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f0f5dba4590>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f0f5dba4540>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f0cf9225a50>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[ 37,  37,  37,  ...,   0,   0,   0],
           │    │     │         │                   [ 36,  36,  36,  ...,   0,   0,   0],
           │    │     │         │                   [ 35,  3...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f0d0ab6b4c0>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[ 37,  37,  37,  ...,   0,   0,   0],
           │    │              │     │                           [ 36,  36,  36,  ...,   0,   0,   0],
           │    │              │     │                           [ 35,  3...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f0d13231a20>
           └ <silk.flow.Flow object at 0x7f0d0ab6b4c0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[ 37,  37,  37,  ...,   0,   0,   0],
    │       │        │    │            │      │                    [ 36,  36,  36,  ...,   0,   0,   0],
    │       │        │    │            │      │                    [ 35,  3...
    │       │        │    │            │      └ [None, None, tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
    │       │        │    │            │                  [-0.7176, -0.7176, -0.7176,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f0d097c5030>, <silk.flow._InputExtraction object at 0x7f0d097c5600>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f0d0ab6b4c0>
    │       └ 4
    └ [None, None, tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
                [-0.7176, -0.7176, -0.7176,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f0f5dba4590>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
           │    │          │         │                   [-0.7176, -0.7176, -0.71...
           │    │          │         └ <property object at 0x7f0f5dba4540>
           │    │          └ <BoundArguments (x=tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
           │    │                      [-0.7176, -0.7176, -0.71...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7f0cf92279d0>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
                                                 │    │                   [-0.7098, -0.7098, -0.7098,  ..., -1.0000, ...
                                                 │    └ <function DepthPro.forward at 0x7f0d174a76d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
                │                        [-0.7098, -0.7098, -0.7098,  ..., -1.0000, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
           │    │                       [-0.7098, -0.7098, -0.7098,  ..., -1.0000,...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.7098, -0.7098, -0.7098,  ..., -1.0000, -1.0000, -1.0000],
           │                         [-0.7098, -0.7098, -0.7098,  ..., -1.0000,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[-0.7098, -0.7098, -0.7098,  ...,  1.0000,  1.0000,  1.0000],
                          │                              [-0.7098, -0.7098, -0.7098,  ...,  1.0000, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.7098, -0.7098, -0.7098,  ...,  1.0000,  1.0000,  1.0000],
           │    │                       [-0.7098, -0.7098, -0.7098,  ...,  1.0000,...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.7098, -0.7098, -0.7098,  ...,  1.0000,  1.0000,  1.0000],
           │                         [-0.7098, -0.7098, -0.7098,  ...,  1.0000,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
        │                      [ 0.0354,  0.0864,  0.0187,  ...,  0.0414,  0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │    │                      [ 0.0354,  0.0864,  0.0187,  ...,  0.0414,  ...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │                        [ 0.0354,  0.0864,  0.0187,  ...,  0.0414,  ...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1398,  0.0357, -0.2730,  ..., -0.2747,  0.1313,  0.2966],
            │                 [-0.0055, -0.1731, -0.0696,  ..., -0.0573, -0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1398,  0.0357, -0.2730,  ..., -0.2747,  0.1313,  0.2966],
           │    │                      [-0.0055, -0.1731, -0.0696,  ..., -0.0573, -...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1398,  0.0357, -0.2730,  ..., -0.2747,  0.1313,  0.2966],
           │                        [-0.0055, -0.1731, -0.0696,  ..., -0.0573, -...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 1.9705e-01, -8.4175e-02, -2.6841e-01,  ..., -4.1119e-01,
        │   │               │        │        │                       1.5074e-01,  2.8768e-01],
        │   │               │        │        │                     [ 8.2293e-0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 1.9705e-01, -8.4175e-02, -2.6841e-01,  ..., -4.1119e-01,
                     1.5074e-01,  2.8768e-01],
                   [ 8.2293e-0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 7.2328e-01, -3.2646e-01, -9.2376e-01,  ..., -1.5014e+00,
           │    │                        5.2485e-01,  7.6171e-01],
           │    │                      [ 5.0007e-...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 7.2328e-01, -3.2646e-01, -9.2376e-01,  ..., -1.5014e+00,
           │                          5.2485e-01,  7.6171e-01],
           │                        [ 5.0007e-...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 43, in forward
    x = self.act(x)
        │        └ tensor([[[-1.6425e+00, -1.5287e-01, -1.8907e+00,  ..., -1.7404e+00,
        │                    -2.8694e+00, -1.3167e-01],
        │                   [-5.9825e-0...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.6425e+00, -1.5287e-01, -1.8907e+00,  ..., -1.7404e+00,
           │    │                       -2.8694e+00, -1.3167e-01],
           │    │                      [-5.9825e-...
           │    └ <function Module._call_impl at 0x7f0e0bdc4700>
           └ GELU(approximate='none')
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.6425e+00, -1.5287e-01, -1.8907e+00,  ..., -1.7404e+00,
           │                         -2.8694e+00, -1.3167e-01],
           │                        [-5.9825e-...
           └ <bound method GELU.forward of GELU(approximate='none')>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 682, in forward
    return F.gelu(input, approximate=self.approximate)
           │ │    │                  │    └ 'none'
           │ │    │                  └ GELU(approximate='none')
           │ │    └ tensor([[[-1.6425e+00, -1.5287e-01, -1.8907e+00,  ..., -1.7404e+00,
           │ │                -2.8694e+00, -1.3167e-01],
           │ │               [-5.9825e-0...
           │ └ <built-in function gelu>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 632.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 444.25 MiB is free. Process 68616 has 47.08 GiB memory in use. Of the allocated memory 46.09 GiB is allocated by PyTorch, and 322.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 11:44:34.418 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:46:25.566 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:46:25.566 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:46:29.081 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:46:57.547 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (37597), thread 'MainThread' (140219796373952):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f8776572e40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f877703ef80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f8776572e40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f8775c32440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f87765b1d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f87765b1e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f87765b1cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f8775ab6440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f87764f72e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f8775cc18a0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f87765b0ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f8775c323b0>
    │   └ <property object at 0x7f87765daf70>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f8775c31750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f8775c316c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f8776ea9bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f8775ab6a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f85224aba30>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f85123abe20>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f853bcf7a30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f853bcf7910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f853bd0c430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f853bd0c670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
    │    └ <property object at 0x7f853bd013a0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f853bd0c700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f85123e6d70>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f853bd0c820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f853bd02e30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f85123e5690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f853bca6d40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f85123e6020>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f85123aab00>
    │    │          └ <function Loop.run at 0x7f853bc32b90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f85123e7be0>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f85123e6020>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f85123aab00>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f853bc8fb50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f85123e7be0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7f853bc32b90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f85123e5c90>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f85123e7be0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7f853bc8c8b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f85123e5c90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7f853bc32b90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f85123e5840>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f85123e5c90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7f853bc8c160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f85123e5840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f853bc8c280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f85123e5840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f853bc8c670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f85123e5840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f853bd12320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
    │         └ <function LightningOptimizer.step at 0x7f857ee1e7a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f8512371fd0 to Trainer at 0x7f85123e5690>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f857eefc790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f85123e64a0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f85123e7760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f85224fd2d0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f8624a3feb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f8624a3fe20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f853bc7fbe0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f868ca5eb00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7f853bc2c360>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f85123e5840>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f857eea9b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f85123e6d70>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f85123e7760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7f857ee8f010>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f85123e6d70>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f8624a003a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f8526bdf760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f85123be350>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f85123be350>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f85123be350>
           │    │     └ <function Flow.flow_from_tape at 0x7f852c419a20>
           │    └ <silk.flow.Flow object at 0x7f85123be4a0>
           └ <silk.flow.FixedOutputFlow object at 0x7f85123be350>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f85123be380>, <silk.flow._InputExtraction object at 0x7f85123be2c0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f85123be4a0>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f8776d3c5e0>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f8776d3c590>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f85123bdb10>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[ 58,  40,  45,  ...,  13,   6,  12],
           │    │     │         │                   [ 36,  41,  44,  ...,  13,   6,  10],
           │    │     │         │                   [ 48,  4...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f8526c0f520>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[ 58,  40,  45,  ...,  13,   6,  12],
           │    │              │     │                           [ 36,  41,  44,  ...,  13,   6,  10],
           │    │              │     │                           [ 48,  4...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f852c419a20>
           └ <silk.flow.Flow object at 0x7f8526c0f520>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[ 58,  40,  45,  ...,  13,   6,  12],
    │       │        │    │            │      │                    [ 36,  41,  44,  ...,  13,   6,  10],
    │       │        │    │            │      │                    [ 48,  4...
    │       │        │    │            │      └ [None, None, tensor([[[[-0.5451, -0.6863, -0.6471,  ..., -0.8980, -0.9529, -0.9059],
    │       │        │    │            │                  [-0.7176, -0.6784, -0.6549,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f8522959090>, <silk.flow._InputExtraction object at 0x7f8522959660>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f8526c0f520>
    │       └ 4
    └ [None, None, tensor([[[[-0.5451, -0.6863, -0.6471,  ..., -0.8980, -0.9529, -0.9059],
                [-0.7176, -0.6784, -0.6549,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f8776d3c5e0>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[-0.5451, -0.6863, -0.6471,  ..., -0.8980, -0.9529, -0.9059],
           │    │          │         │                   [-0.7176, -0.6784, -0.65...
           │    │          │         └ <property object at 0x7f8776d3c590>
           │    │          └ <BoundArguments (x=tensor([[[[-0.5451, -0.6863, -0.6471,  ..., -0.8980, -0.9529, -0.9059],
           │    │                      [-0.7176, -0.6784, -0.65...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7f85123bfa90>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[-0.5451, -0.6456, -0.6659,  ..., -0.9244, -0.9394, -0.9059],
                                                 │    │                   [-0.5451, -0.6456, -0.6659,  ..., -0.9244, ...
                                                 │    └ <function DepthPro.forward at 0x7f853068f6d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[-0.5451, -0.6456, -0.6659,  ..., -0.9244, -0.9394, -0.9059],
                │                        [-0.5451, -0.6456, -0.6659,  ..., -0.9244, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.5451, -0.6456, -0.6659,  ..., -0.9244, -0.9394, -0.9059],
           │    │                       [-0.5451, -0.6456, -0.6659,  ..., -0.9244,...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.5451, -0.6456, -0.6659,  ..., -0.9244, -0.9394, -0.9059],
           │                         [-0.5451, -0.6456, -0.6659,  ..., -0.9244,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[-0.5451, -0.6456, -0.6659,  ...,  0.9614,  0.9614,  0.9795],
                          │                              [-0.5451, -0.6456, -0.6659,  ...,  0.9614, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.5451, -0.6456, -0.6659,  ...,  0.9614,  0.9614,  0.9795],
           │    │                       [-0.5451, -0.6456, -0.6659,  ...,  0.9614,...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.5451, -0.6456, -0.6659,  ...,  0.9614,  0.9614,  0.9795],
           │                         [-0.5451, -0.6456, -0.6659,  ...,  0.9614,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 1.2436e-02, -5.0049e-03, -1.2978e-02,  ..., -9.7656e-03,
        │                        7.1678e-03, -2.7370e-03],
        │                      [ 3.6338e-0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 1.2436e-02, -5.0049e-03, -1.2978e-02,  ..., -9.7656e-03,
           │    │                        7.1678e-03, -2.7370e-03],
           │    │                      [ 3.6338e-...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 1.2436e-02, -5.0049e-03, -1.2978e-02,  ..., -9.7656e-03,
           │                          7.1678e-03, -2.7370e-03],
           │                        [ 3.6338e-...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1214,  0.0549, -0.2019,  ..., -0.3449,  0.0992,  0.3559],
            │                 [-0.0212, -0.1090, -0.1138,  ...,  0.0199, -0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1214,  0.0549, -0.2019,  ..., -0.3449,  0.0992,  0.3559],
           │    │                      [-0.0212, -0.1090, -0.1138,  ...,  0.0199, -...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1214,  0.0549, -0.2019,  ..., -0.3449,  0.0992,  0.3559],
           │                        [-0.0212, -0.1090, -0.1138,  ...,  0.0199, -...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 1.5616e-01, -6.8338e-02, -2.2097e-01,  ..., -4.9951e-01,
        │   │               │        │        │                       1.4603e-01,  3.1908e-01],
        │   │               │        │        │                     [ 4.7265e-0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 1.5616e-01, -6.8338e-02, -2.2097e-01,  ..., -4.9951e-01,
                     1.4603e-01,  3.1908e-01],
                   [ 4.7265e-0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 5.2586e-01, -2.6592e-01, -7.3131e-01,  ..., -1.7281e+00,
           │    │                        4.7811e-01,  8.1318e-01],
           │    │                      [ 2.4131e-...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 5.2586e-01, -2.6592e-01, -7.3131e-01,  ..., -1.7281e+00,
           │                          4.7811e-01,  8.1318e-01],
           │                        [ 2.4131e-...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 46, in forward
    x = self.fc2(x)
        │        └ tensor([[[-0.0892, -0.0286, -0.0226,  ..., -0.0936, -0.0079, -0.0675],
        │                   [-0.1693, -0.1380, -0.1452,  ..., -0.0060, -0...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-0.0892, -0.0286, -0.0226,  ..., -0.0936, -0.0079, -0.0675],
           │    │                      [-0.1693, -0.1380, -0.1452,  ..., -0.0060, -...
           │    └ <function Module._call_impl at 0x7f8624fbc700>
           └ Linear(in_features=4096, out_features=1024, bias=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-0.0892, -0.0286, -0.0226,  ..., -0.0936, -0.0079, -0.0675],
           │                        [-0.1693, -0.1380, -0.1452,  ..., -0.0060, -...
           └ <bound method Linear.forward of Linear(in_features=4096, out_features=1024, bias=True)>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           │ │      │      │            └ Linear(in_features=4096, out_features=1024, bias=True)
           │ │      │      └ Linear(in_features=4096, out_features=1024, bias=True)
           │ │      └ tensor([[[-0.0892, -0.0286, -0.0226,  ..., -0.0936, -0.0079, -0.0675],
           │ │                 [-0.1693, -0.1380, -0.1452,  ..., -0.0060, -0...
           │ └ <built-in function linear>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 158.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 40.25 MiB is free. Process 72105 has 47.47 GiB memory in use. Of the allocated memory 46.71 GiB is allocated by PyTorch, and 92.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 11:46:58.766 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:56:13.980 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:56:13.981 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:56:17.483 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:56:39.865 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 11:59:05.620 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 11:59:05.621 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 11:59:09.139 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 11:59:31.336 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:00:42.922 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:00:42.923 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:00:46.443 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:01:08.772 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:02:50.555 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:02:50.556 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:02:54.084 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:03:16.117 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:03:47.663 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:03:47.664 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:03:51.183 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:04:13.401 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:07:52.159 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:07:52.160 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:07:55.678 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:08:17.791 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:09:04.811 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:09:04.812 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:09:08.325 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:09:34.707 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (51963), thread 'MainThread' (140273749107136):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f94062dae40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f9406d9af80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f94062dae40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f94059a6440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f9406319d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f9406319e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f9406319cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f9405816440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f94062632e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f9405a2d990>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f9406318ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f94059a63b0>
    │   └ <property object at 0x7f9406343100>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f94059a5750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f94059a56c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f9406bfdbd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f9405816a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f91b2217a00>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f91a211bdf0>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f91cba3fa30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f91cba3f910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f91cba58430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f91cba58670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
    │    └ <property object at 0x7f91cba4d260>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f91cba58700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f91a2154cd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f91cba58820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f91cba4ecf0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f91a2157610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f91cb9f2d40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f91a21578e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f91a211ab90>
    │    │          └ <function Loop.run at 0x7f91cbb7ab90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f91a21567d0>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f91a21578e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f91a211ab90>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f91cb9dbb50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f91a21567d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7f91cbb7ab90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f91a2155f00>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f91a21567d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7f91cb9d88b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f91a2155f00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7f91cbb7ab90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f91a2155a50>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f91a2155f00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7f91cb9d8160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f91a2155a50>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f91cb9d8280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f91a2155a50>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f91cb9d8670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f91a2155a50>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f91cba5e320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
    │         └ <function LightningOptimizer.step at 0x7f920eb7a7a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f91b3270130 to Trainer at 0x7f91a2157610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f92b3ee4790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f91a2157070>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f91a21551b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f91b22252d0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f92b4847eb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f92b4847e20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f91cb9c7be0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f91a1dfa6b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7f91cbb74130>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f91a2155a50>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f920ec05b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f91a2154cd0>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f91a21551b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7f920ebeb3d0>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f91a2154cd0>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f92b480c3a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f91b391b760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f91a212e380>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f91a212e380>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f91a212e380>
           │    │     └ <function Flow.flow_from_tape at 0x7f91bc111a20>
           │    └ <silk.flow.Flow object at 0x7f91a212e410>
           └ <silk.flow.FixedOutputFlow object at 0x7f91a212e380>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f91a212e290>, <silk.flow._InputExtraction object at 0x7f91a212e1d0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f91a212e410>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f9406a88590>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f9406a88540>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f91a212da50>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[  2,   0,   0,  ...,   0,   0,   0],
           │    │     │         │                   [  0,   1,   0,  ...,  17,   1,   0],
           │    │     │         │                   [  0,   ...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f91b394f730>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[  2,   0,   0,  ...,   0,   0,   0],
           │    │              │     │                           [  0,   1,   0,  ...,  17,   1,   0],
           │    │              │     │                           [  0,   ...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f91bc111a20>
           └ <silk.flow.Flow object at 0x7f91b394f730>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[  2,   0,   0,  ...,   0,   0,   0],
    │       │        │    │            │      │                    [  0,   1,   0,  ...,  17,   1,   0],
    │       │        │    │            │      │                    [  0,   ...
    │       │        │    │            │      └ [None, None, tensor([[[[-0.9843, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
    │       │        │    │            │                  [-1.0000, -0.9922, -1.0000,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f91b26d5150>, <silk.flow._InputExtraction object at 0x7f91b26d5720>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f91b394f730>
    │       └ 4
    └ [None, None, tensor([[[[-0.9843, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
                [-1.0000, -0.9922, -1.0000,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f9406a88590>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[-0.9843, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │    │          │         │                   [-1.0000, -0.9922, -1.00...
           │    │          │         └ <property object at 0x7f9406a88540>
           │    │          └ <BoundArguments (x=tensor([[[[-0.9843, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │    │                      [-1.0000, -0.9922, -1.00...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7f91a212f9d0>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[-0.9843, -0.9955, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
                                                 │    │                   [-0.9843, -0.9955, -1.0000,  ..., -1.0000, ...
                                                 │    └ <function DepthPro.forward at 0x7f91c038b6d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[-0.9843, -0.9955, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
                │                        [-0.9843, -0.9955, -1.0000,  ..., -1.0000, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.9843, -0.9955, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │    │                       [-0.9843, -0.9955, -1.0000,  ..., -1.0000,...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.9843, -0.9955, -1.0000,  ..., -1.0000, -1.0000, -1.0000],
           │                         [-0.9843, -0.9955, -1.0000,  ..., -1.0000,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[-0.9843, -0.9955, -1.0000,  ...,  0.6880,  0.6839,  0.5843],
                          │                              [-0.9843, -0.9955, -1.0000,  ...,  0.6880, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.9843, -0.9955, -1.0000,  ...,  0.6880,  0.6839,  0.5843],
           │    │                       [-0.9843, -0.9955, -1.0000,  ...,  0.6880,...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.9843, -0.9955, -1.0000,  ...,  0.6880,  0.6839,  0.5843],
           │                         [-0.9843, -0.9955, -1.0000,  ...,  0.6880,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
        │                      [ 0.0290,  0.1024,  0.0217,  ...,  0.0427,  0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │    │                      [ 0.0290,  0.1024,  0.0217,  ...,  0.0427,  ...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │                        [ 0.0290,  0.1024,  0.0217,  ...,  0.0427,  ...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 1.0727e-01,  9.0109e-03, -2.1480e-01,  ..., -3.0830e-01,
            │                   7.7002e-02,  2.5137e-01],
            │                 [ 1.6356e-0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 1.0727e-01,  9.0109e-03, -2.1480e-01,  ..., -3.0830e-01,
           │    │                        7.7002e-02,  2.5137e-01],
           │    │                      [ 1.6356e-...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 1.0727e-01,  9.0109e-03, -2.1480e-01,  ..., -3.0830e-01,
           │                          7.7002e-02,  2.5137e-01],
           │                        [ 1.6356e-...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 0.1215, -0.1547, -0.2659,  ..., -0.4608,  0.1094,  0.2070],
        │   │               │        │        │                     [ 0.2025, -0.1899, -0.0368,  ..., -0.2666, -0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 0.1215, -0.1547, -0.2659,  ..., -0.4608,  0.1094,  0.2070],
                   [ 0.2025, -0.1899, -0.0368,  ..., -0.2666, -0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.3825, -0.5717, -0.8864,  ..., -1.6077,  0.3315,  0.5004],
           │    │                      [ 1.4102, -1.3083, -0.2213,  ..., -1.7586, -...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.3825, -0.5717, -0.8864,  ..., -1.6077,  0.3315,  0.5004],
           │                        [ 1.4102, -1.3083, -0.2213,  ..., -1.7586, -...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 46, in forward
    x = self.fc2(x)
        │        └ tensor([[[-7.4991e-02, -5.6491e-02, -1.9838e-02,  ..., -1.5782e-01,
        │                    -7.6341e-03, -5.1968e-02],
        │                   [-1.6497e-0...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-7.4991e-02, -5.6491e-02, -1.9838e-02,  ..., -1.5782e-01,
           │    │                       -7.6341e-03, -5.1968e-02],
           │    │                      [-1.6497e-...
           │    └ <function Module._call_impl at 0x7f92b4bc8700>
           └ Linear(in_features=4096, out_features=1024, bias=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-7.4991e-02, -5.6491e-02, -1.9838e-02,  ..., -1.5782e-01,
           │                         -7.6341e-03, -5.1968e-02],
           │                        [-1.6497e-...
           └ <bound method Linear.forward of Linear(in_features=4096, out_features=1024, bias=True)>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           │ │      │      │            └ Linear(in_features=4096, out_features=1024, bias=True)
           │ │      │      └ Linear(in_features=4096, out_features=1024, bias=True)
           │ │      └ tensor([[[-7.4991e-02, -5.6491e-02, -1.9838e-02,  ..., -1.5782e-01,
           │ │                  -7.6341e-03, -5.1968e-02],
           │ │                 [-1.6497e-0...
           │ └ <built-in function linear>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 158.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 14.25 MiB is free. Process 86626 has 47.50 GiB memory in use. Of the allocated memory 46.71 GiB is allocated by PyTorch, and 120.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 12:09:35.968 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:10:20.602 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:10:20.602 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:10:24.111 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:10:50.145 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (55364), thread 'MainThread' (139879723864512):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f38486dee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f38491d2f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f38486dee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f3847de2440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f384871dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f384871de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f384871dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f3847c5a440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f38486672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f3847e71900>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f384871cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f3847de23b0>
    │   └ <property object at 0x7f3848c7df30>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f3847de1750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f3847de16c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f3849039bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f3847c5aa70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f35e4523d00>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f35f45d3e50>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f360deafa30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f360deaf910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f360dec8430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f360dec8670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
    │    └ <property object at 0x7f360debd350>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f360dec8700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f35f460e860>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f360dec8820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f360debede0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f35f460c760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f360de62d40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f35f460c640>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f35f43c1b10>
    │    │          └ <function Loop.run at 0x7f360ddeeb90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f35f460e320>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f35f460c640>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f35f43c1b10>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f360de4bb50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f35f460e320>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7f360ddeeb90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f35f460f700>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f35f460e320>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7f360de488b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f35f460f700>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7f360ddeeb90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f35f460e0e0>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f35f460f700>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7f360de48160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f35f460e0e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f360de48280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f35f460e0e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f360de48670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f35f460e0e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f360dcca320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
    │         └ <function LightningOptimizer.step at 0x7f365100e7a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f35e4569940 to Trainer at 0x7f35f460c760>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f36510f0790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f35f460efb0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f35f460ceb0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f35e45552d0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f36f6c4beb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f36f6c4be20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f360de3bbe0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f35f42ee920>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7f360dde8400>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f35f460e0e0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f365109db40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f35f460e860>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f35f460ceb0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7f3651082c50>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f35f460e860>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f36f6c083a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f35fe6e3760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f35f45ee320>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f35f45ee320>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f35f45ee320>
           │    │     └ <function Flow.flow_from_tape at 0x7f35fe7d9a20>
           │    └ <silk.flow.Flow object at 0x7f35f45ee4a0>
           └ <silk.flow.FixedOutputFlow object at 0x7f35f45ee320>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f35f45ee380>, <silk.flow._InputExtraction object at 0x7f35f45ee2f0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f35f45ee4a0>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f3848ecc450>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f3848ecc400>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f35f45edb10>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[ 45,  45,  45,  ...,   8,   8,   7],
           │    │     │         │                   [ 44,  44,  44,  ...,   5,   6,   5],
           │    │     │         │                   [ 43,  4...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f35f8dcf580>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[ 45,  45,  45,  ...,   8,   8,   7],
           │    │              │     │                           [ 44,  44,  44,  ...,   5,   6,   5],
           │    │              │     │                           [ 43,  4...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f35fe7d9a20>
           └ <silk.flow.Flow object at 0x7f35f8dcf580>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[ 45,  45,  45,  ...,   8,   8,   7],
    │       │        │    │            │      │                    [ 44,  44,  44,  ...,   5,   6,   5],
    │       │        │    │            │      │                    [ 43,  4...
    │       │        │    │            │      └ [None, None, tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
    │       │        │    │            │                  [-0.6549, -0.6549, -0.6549,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f35f4aa1000>, <silk.flow._InputExtraction object at 0x7f35f4aa15d0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f35f8dcf580>
    │       └ 4
    └ [None, None, tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
                [-0.6549, -0.6549, -0.6549,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f3848ecc450>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
           │    │          │         │                   [-0.6549, -0.6549, -0.65...
           │    │          │         └ <property object at 0x7f3848ecc400>
           │    │          └ <BoundArguments (x=tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9373, -0.9451],
           │    │                      [-0.6549, -0.6549, -0.65...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7f35f45efa90>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
                                                 │    │                   [-0.6471, -0.6471, -0.6471,  ..., -0.9373, ...
                                                 │    └ <function DepthPro.forward at 0x7f360280f6d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
                │                        [-0.6471, -0.6471, -0.6471,  ..., -0.9373, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
           │    │                       [-0.6471, -0.6471, -0.6471,  ..., -0.9373,...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ..., -0.9373, -0.9395, -0.9451],
           │                         [-0.6471, -0.6471, -0.6471,  ..., -0.9373,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[-0.6471, -0.6471, -0.6471,  ...,  1.0000,  1.0000,  1.0000],
                          │                              [-0.6471, -0.6471, -0.6471,  ...,  1.0000, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ...,  1.0000,  1.0000,  1.0000],
           │    │                       [-0.6471, -0.6471, -0.6471,  ...,  1.0000,...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-0.6471, -0.6471, -0.6471,  ...,  1.0000,  1.0000,  1.0000],
           │                         [-0.6471, -0.6471, -0.6471,  ...,  1.0000,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
        │                      [ 0.0359,  0.0849,  0.0150,  ...,  0.0380,  0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │    │                      [ 0.0359,  0.0849,  0.0150,  ...,  0.0380,  ...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.0124, -0.0050, -0.0130,  ..., -0.0098,  0.0072, -0.0027],
           │                        [ 0.0359,  0.0849,  0.0150,  ...,  0.0380,  ...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1400,  0.0346, -0.2510,  ..., -0.2697,  0.1182,  0.2969],
            │                 [-0.0113, -0.1870, -0.0645,  ..., -0.0569, -0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1400,  0.0346, -0.2510,  ..., -0.2697,  0.1182,  0.2969],
           │    │                      [-0.0113, -0.1870, -0.0645,  ..., -0.0569, -...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1400,  0.0346, -0.2510,  ..., -0.2697,  0.1182,  0.2969],
           │                        [-0.0113, -0.1870, -0.0645,  ..., -0.0569, -...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 1.9543e-01, -8.0575e-02, -2.4498e-01,  ..., -3.8212e-01,
        │   │               │        │        │                       1.4641e-01,  2.9856e-01],
        │   │               │        │        │                     [ 8.3934e-0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 1.9543e-01, -8.0575e-02, -2.4498e-01,  ..., -3.8212e-01,
                     1.4641e-01,  2.9856e-01],
                   [ 8.3934e-0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 7.1912e-01, -3.1130e-01, -8.3788e-01,  ..., -1.4083e+00,
           │    │                        5.0998e-01,  7.9439e-01],
           │    │                      [ 5.1606e-...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 7.1912e-01, -3.1130e-01, -8.3788e-01,  ..., -1.4083e+00,
           │                          5.0998e-01,  7.9439e-01],
           │                        [ 5.1606e-...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 43, in forward
    x = self.act(x)
        │        └ tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
        │                   [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -1...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
           │    │                      [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -...
           │    └ <function Module._call_impl at 0x7f36f6fcc700>
           └ GELU(approximate='none')
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
           │                        [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -...
           └ <bound method GELU.forward of GELU(approximate='none')>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 682, in forward
    return F.gelu(input, approximate=self.approximate)
           │ │    │                  │    └ 'none'
           │ │    │                  └ GELU(approximate='none')
           │ │    └ tensor([[[-1.6303, -0.1255, -1.9722,  ..., -1.7452, -2.8740, -0.1438],
           │ │               [-0.6336, -0.2593, -0.6324,  ..., -2.9843, -1...
           │ └ <built-in function gelu>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 632.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 444.25 MiB is free. Process 90038 has 47.08 GiB memory in use. Of the allocated memory 46.09 GiB is allocated by PyTorch, and 322.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 12:10:51.343 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:15:38.619 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:15:38.620 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:15:42.169 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:16:08.529 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (58765), thread 'MainThread' (139789067837888):
Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f232cedae40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f232d986f80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f232cedae40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f232c5a6440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f232cf19d80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f232cf19e10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f232cf19cf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f232c402440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f232ce632e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f232c62d930>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f232cf18ee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f232c5a63b0>
    │   └ <property object at 0x7f232cf43060>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f232c5a5750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f232c5a56c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f232d7e9bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f232c402a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f20d8e087f0>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f20c8d0fe20>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f20f2627a30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f20f2627910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f20f2640430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f20f2640670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
    │    └ <property object at 0x7f20f2635210>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f20f2640700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f20c8d48970>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f20f2640820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f20f2636ca0>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f20c8d4a770>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f20f25dad40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f20c8d4af80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f20c8d0ebc0>
    │    │          └ <function Loop.run at 0x7f20f2766b90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f20c8d48610>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f20c8d4af80>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f20c8d0ebc0>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f20f25c3b50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f20c8d48610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 0
                   │    │          │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                   │    │          │                [ 44.,  44.,  44.,  ...,   5.,   6....
                   │    │          └ <function Loop.run at 0x7f20f2766b90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f20c8d4b6d0>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f20c8d48610>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function TrainingBatchLoop.advance at 0x7f20f25c08b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f20c8d4b6d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 0
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
              │    │              │                [ 44.,  44.,  44.,  ...,   5.,   6....
              │    │              └ <function Loop.run at 0x7f20f2766b90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f20c8d4a0b0>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f20c8d4b6d0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │    │                     [ 44.,  44.,  44.,  ...,   5.,   6...
    │    └ <function OptimizerLoop.advance at 0x7f20f25c0160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f20c8d4a0b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f20f25c0280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f20c8d4a0b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
    │    │               │          │        └ 0
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f20f25c0670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f20c8d4a0b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f20f2646320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
    │         └ <function LightningOptimizer.step at 0x7f21357767a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f20c8d11760 to Trainer at 0x7f20c8d4a770>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f21daae0790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f20c8d4bcd0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f20c8d4abc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f20d8e192d0>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f21db443eb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f21db443e20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f20f25afbe0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f2245d217b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                           │    │                                              [ 44.,  44.,...
                           │    └ <property object at 0x7f20f2760220>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f20c8d4a0b0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                    │                           [ 44.,  44.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f2135801b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f20c8d48970>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f20c8d4abc0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                   [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <property object at 0x7f21357e7150>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f20c8d48970>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
         │    │                              [ 44.,  44.,  44.,  ...,   5.,   6...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f21db4083a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                         [ 44.,  44.,  44.,  ...,   5.,   6...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │                        [ 44.,  44.,  44.,  ...,   5.,   6...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │                          [ 44.,  44.,  44.,  ...,   5.,   6...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
             │                                       [ 44.,  44.,  44.,  ...,   5.,   6...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f20da507760>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
                                     │    │                     [ 44.,  44.,  44.,  ...,   5.,   6....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f20c8d2e2f0>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
           │    │     │              │    │      │    │                             [ 44.,  44.,  44.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f20c8d2e2f0>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f20c8d2e2f0>
           │    │     └ <function Flow.flow_from_tape at 0x7f20e2d01a20>
           │    └ <silk.flow.Flow object at 0x7f20c8d2e470>
           └ <silk.flow.FixedOutputFlow object at 0x7f20c8d2e2f0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[ 45.,  45.,  45.,  ...,   8.,   8.,   7.],
    │       │        │    │            │      │                     [ 44.,  44.,  44.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
    │       │        │    │            │                  [0.1939, 0.1883, 0.1855,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f20c8d2e350>, <silk.flow._InputExtraction object at 0x7f20c8d2e2c0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f20c8d2e470>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.1894, 0.1832, 0.1832,  ..., 0.0314, 0.0277, 0.0235],
                [0.1939, 0.1883, 0.1855,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f232d674590>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f232d674540>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f20c8d2dae0>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[ 0,  0,  0,  ...,  0,  4,  0],
           │    │     │         │                   [ 0,  5,  6,  ...,  0,  0,  1],
           │    │     │         │                   [ 8,  0,  0,  ...,  ...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f20da53b5e0>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[ 0,  0,  0,  ...,  0,  4,  0],
           │    │              │     │                           [ 0,  5,  6,  ...,  0,  0,  1],
           │    │              │     │                           [ 8,  0,  0,  ...,  ...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f20e2d01a20>
           └ <silk.flow.Flow object at 0x7f20da53b5e0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[ 0,  0,  0,  ...,  0,  4,  0],
    │       │        │    │            │      │                    [ 0,  5,  6,  ...,  0,  0,  1],
    │       │        │    │            │      │                    [ 8,  0,  0,  ...,  ...
    │       │        │    │            │      └ [None, None, tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],
    │       │        │    │            │                  [-1.0000, -0.9608, -0.9529,  ....
    │       │        │    │            └ 4
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f20d92bcfd0>, <silk.flow._InputExtraction object at 0x7f20d92bd5a0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f20da53b5e0>
    │       └ 4
    └ [None, None, tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],
                [-1.0000, -0.9608, -0.9529,  ....

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f232d674590>
           │    │          │         │       └ <BoundArguments (x=tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],
           │    │          │         │                   [-1.0000, -0.9608, -0.95...
           │    │          │         └ <property object at 0x7f232d674540>
           │    │          └ <BoundArguments (x=tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9686, -1.0000],
           │    │                      [-1.0000, -0.9608, -0.95...
           │    └ <bound method DepthPro.infer_sj of DepthPro(
           │        (encoder): DepthProEncoder(
           │          (patch_encoder): VisionTransformer(
           │            (pat...
           └ <silk.flow._FunctionCall object at 0x7f20c8d2fa60>

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 559, in infer_sj
    canonical_inverse_depth, kpt_logits, descs = self.forward(x)
                                                 │    │       └ tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -0.9849, -0.9777, -1.0000],
                                                 │    │                   [-1.0000, -1.0000, -1.0000,  ..., -0.9849, ...
                                                 │    └ <function DepthPro.forward at 0x7f20e6f7b6d0>
                                                 └ DepthPro(
                                                     (encoder): DepthProEncoder(
                                                       (patch_encoder): VisionTransformer(
                                                         (patch_embed): PatchEmbed(
                                                           (pro...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/depth_pro.py", line 496, in forward
    encodings = self.encoder(x)
                │            └ tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -0.9849, -0.9777, -1.0000],
                │                        [-1.0000, -1.0000, -1.0000,  ..., -0.9849, ...
                └ DepthPro(
                    (encoder): DepthProEncoder(
                      (patch_encoder): VisionTransformer(
                        (patch_embed): PatchEmbed(
                          (pro...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -0.9849, -0.9777, -1.0000],
           │    │                       [-1.0000, -1.0000, -1.0000,  ..., -0.9849,...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed(
                   (proj): Conv2d(3, 1024, kernel_si...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -0.9849, -0.9777, -1.0000],
           │                         [-1.0000, -1.0000, -1.0000,  ..., -0.9849,...
           └ <bound method DepthProEncoder.forward of DepthProEncoder(
               (patch_encoder): VisionTransformer(
                 (patch_embed): PatchEmbed...

  File "/root/silk/silk/backbones/depthpro/ml_depth_pro/src/depth_pro/network/encoder.py", line 266, in forward
    x_pyramid_encodings = self.patch_encoder(x_pyramid_patches)
                          │                  └ tensor([[[[-1.0000, -1.0000, -1.0000,  ...,  0.1958,  0.2000,  0.2027],
                          │                              [-1.0000, -1.0000, -1.0000,  ...,  0.1958, ...
                          └ DepthProEncoder(
                              (patch_encoder): VisionTransformer(
                                (patch_embed): PatchEmbed(
                                  (proj): Conv2d(3, 1024, kernel_si...

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ...,  0.1958,  0.2000,  0.2027],
           │    │                       [-1.0000, -1.0000, -1.0000,  ...,  0.1958,...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
                 (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[[-1.0000, -1.0000, -1.0000,  ...,  0.1958,  0.2000,  0.2027],
           │                         [-1.0000, -1.0000, -1.0000,  ...,  0.1958,...
           └ <bound method VisionTransformer.forward_features of VisionTransformer(
               (patch_embed): PatchEmbed(
                 (proj): Conv2d(3, 102...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 810, in forward_features
    x = self.blocks(x)
        │           └ tensor([[[ 1.2436e-02, -5.0049e-03, -1.2978e-02,  ..., -9.7656e-03,
        │                        7.1678e-03, -2.7370e-03],
        │                      [ 3.0629e-0...
        └ VisionTransformer(
            (patch_embed): PatchEmbed(
              (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
              (norm)...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 1.2436e-02, -5.0049e-03, -1.2978e-02,  ..., -9.7656e-03,
           │    │                        7.1678e-03, -2.7370e-03],
           │    │                      [ 3.0629e-...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                 (attn): Attention(
                   (q...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 1.2436e-02, -5.0049e-03, -1.2978e-02,  ..., -9.7656e-03,
           │                          7.1678e-03, -2.7370e-03],
           │                        [ 3.0629e-...
           └ <bound method Sequential.forward of Sequential(
               (0): Block(
                 (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=T...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            │      └ tensor([[[ 0.1233, -0.0230, -0.2320,  ..., -0.2886,  0.1009,  0.1592],
            │                 [ 0.0120, -0.1496,  0.0805,  ..., -0.0772,  0...
            └ Block(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): Attention(
                  (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.1233, -0.0230, -0.2320,  ..., -0.2886,  0.1009,  0.1592],
           │    │                      [ 0.0120, -0.1496,  0.0805,  ..., -0.0772,  ...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
                 (qkv): Linear(in_features=1...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.1233, -0.0230, -0.2320,  ..., -0.2886,  0.1009,  0.1592],
           │                        [ 0.0120, -0.1496,  0.0805,  ..., -0.0772,  ...
           └ <bound method Block.forward of Block(
               (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
               (attn): Attention(
             ...
  File "/usr/local/lib/python3.10/dist-packages/timm/models/vision_transformer.py", line 166, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
        │   │               │        │        │          └ tensor([[[ 0.1644, -0.1935, -0.2615,  ..., -0.4055,  0.1508,  0.1156],
        │   │               │        │        │                     [ 0.0732, -0.2580,  0.1415,  ..., -0.1553,  0...
        │   │               │        │        └ Block(
        │   │               │        │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │        │            (attn): Attention(
        │   │               │        │              (qkv): Linear(in_features=1...
        │   │               │        └ Block(
        │   │               │            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │               │            (attn): Attention(
        │   │               │              (qkv): Linear(in_features=1...
        │   │               └ Block(
        │   │                   (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │   │                   (attn): Attention(
        │   │                     (qkv): Linear(in_features=1...
        │   └ Block(
        │       (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        │       (attn): Attention(
        │         (qkv): Linear(in_features=1...
        └ tensor([[[ 0.1644, -0.1935, -0.2615,  ..., -0.4055,  0.1508,  0.1156],
                   [ 0.0732, -0.2580,  0.1415,  ..., -0.1553,  0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[ 0.5728, -0.7187, -0.8872,  ..., -1.4651,  0.5095,  0.2633],
           │    │                      [ 0.4558, -1.6791,  0.9432,  ..., -1.0644,  ...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='none')
               (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[ 0.5728, -0.7187, -0.8872,  ..., -1.4651,  0.5095,  0.2633],
           │                        [ 0.4558, -1.6791,  0.9432,  ..., -1.0644,  ...
           └ <bound method Mlp.forward of Mlp(
               (fc1): Linear(in_features=1024, out_features=4096, bias=True)
               (act): GELU(approximate='...
  File "/usr/local/lib/python3.10/dist-packages/timm/layers/mlp.py", line 43, in forward
    x = self.act(x)
        │        └ tensor([[[-1.6044, -0.1809, -2.5053,  ..., -0.9668, -2.7265, -0.1987],
        │                   [-1.0882, -0.1458, -2.1876,  ..., -3.3214, -0...
        └ Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (tensor([[[-1.6044, -0.1809, -2.5053,  ..., -0.9668, -2.7265, -0.1987],
           │    │                      [-1.0882, -0.1458, -2.1876,  ..., -3.3214, -...
           │    └ <function Module._call_impl at 0x7f21db7c4700>
           └ GELU(approximate='none')
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (tensor([[[-1.6044, -0.1809, -2.5053,  ..., -0.9668, -2.7265, -0.1987],
           │                        [-1.0882, -0.1458, -2.1876,  ..., -3.3214, -...
           └ <bound method GELU.forward of GELU(approximate='none')>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py", line 682, in forward
    return F.gelu(input, approximate=self.approximate)
           │ │    │                  │    └ 'none'
           │ │    │                  └ GELU(approximate='none')
           │ │    └ tensor([[[-1.6044, -0.1809, -2.5053,  ..., -0.9668, -2.7265, -0.1987],
           │ │               [-1.0882, -0.1458, -2.1876,  ..., -3.3214, -0...
           │ └ <built-in function gelu>
           └ <module 'torch.nn.functional' from '/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py'>

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 632.00 MiB. GPU 1 has a total capacity of 47.54 GiB of which 366.25 MiB is free. Process 93469 has 47.16 GiB memory in use. Of the allocated memory 46.09 GiB is allocated by PyTorch, and 399.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-02-05 12:16:09.764 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:19:17.552 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:19:17.553 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:19:21.086 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:23:52.428 | ERROR    | silk.cli:main:111 - An error has been caught in function 'main', process 'MainProcess' (62166), thread 'MainThread' (140316755431872):
Traceback (most recent call last):

  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │                         [127., 127., 127.,  ...,   2.,   2...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │    │                        [127., 127., 127.,  ...,   2.,   2...
           │    └ <function Module._call_impl at 0x7f9cb81cc700>
           └ LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
                   (model): DepthPro(
                     (encoder...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │                          [127., 127., 127.,  ...,   2.,   2...
           └ <bound method _LightningModuleWrapperBase.forward of LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (mod...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/overrides/base.py", line 81, in forward
    output = self.module.training_step(*inputs, **kwargs)
             │                          │         └ {}
             │                          └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
             │                                       [127., 127., 127.,  ...,   2.,   2...
             └ LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
                     (model): DepthPro(
                       (encoder...

  File "/root/silk/silk/models/silk.py", line 348, in training_step
    return self._total_loss(
           │    └ <function SiLKBase._total_loss at 0x7f9bb6f277f0>
           └ SiLKRandomHomographies(
               (model): SJNet(
                 (model): DepthPro(
                   (encoder): DepthProEncoder(
                     (patch_encoder): V...

  File "/root/silk/silk/models/silk.py", line 288, in _total_loss
    loss_1, loss_2, loss_3, loss_4 = self._loss_fn(batch, use_image_aug)
                                     │    │        │      └ True
                                     │    │        └ NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
                                     │    │                     [127., 127., 127.,  ...,   2.,   2....
                                     │    └ <silk.flow.FixedOutputFlow object at 0x7f9ba57361a0>
                                     └ SiLKRandomHomographies(
                                         (model): SJNet(
                                           (model): DepthPro(
                                             (encoder): DepthProEncoder(
                                               (patch_encoder): V...

  File "/root/silk/silk/flow.py", line 307, in __call__
    return self._flow.flow_from_tape(self._tape, self._output_indexes, inputs)
           │    │     │              │    │      │    │                └ {'batch': NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │    │     │              │    │      │    │                             [127., 127., 127.,  ..., ...
           │    │     │              │    │      │    └ (22, 23, 20, 24)
           │    │     │              │    │      └ <silk.flow.FixedOutputFlow object at 0x7f9ba57361a0>
           │    │     │              │    └ ((0, ()), (1, ()), (2, [0]), (3, ()), (4, ()), (5, ()), (6, [2]), (7, [3, 1]), (8, ()), (9, [8, 7]), (10, ()), (13, ()), (14,...
           │    │     │              └ <silk.flow.FixedOutputFlow object at 0x7f9ba57361a0>
           │    │     └ <function Flow.flow_from_tape at 0x7f9bbf719990>
           │    └ <silk.flow.Flow object at 0x7f9ba5736440>
           └ <silk.flow.FixedOutputFlow object at 0x7f9ba57361a0>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'batch': NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
    │       │        │    │            │      │                     [127., 127., 127.,  ..., ...
    │       │        │    │            │      └ [None, None, None, None, tensor([[[[0.7158, 0.7065, 0.6981,  ..., 0.0283, 0.0263, 0.0247],
    │       │        │    │            │                  [0.7166, 0.7110, 0.7054,...
    │       │        │    │            └ 9
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f9ba57362c0>, <silk.flow._InputExtraction object at 0x7f9ba5736230>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f9ba5736440>
    │       └ 9
    └ [None, None, None, None, tensor([[[[0.7158, 0.7065, 0.6981,  ..., 0.0283, 0.0263, 0.0247],
                [0.7166, 0.7110, 0.7054,...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f9e0a094450>
           │    │          │         │       └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    │          │         └ <property object at 0x7f9e0a094400>
           │    │          └ <BoundArguments (outputs=('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors'), args=(), kwa...
           │    └ <bound method AutoForward.forward_flow of SJNet(
           │        (model): DepthPro(
           │          (encoder): DepthProEncoder(
           │            (patch_encoder): ...
           └ <silk.flow._FunctionCall object at 0x7f9ba5735a80>

  File "/root/silk/silk/flow.py", line 332, in forward_flow
    return self._flow(outputs, *args, **kwargs)
           │    │     │         │       └ {'images': tensor([[[[126, 126, 126,  ...,   4,   4,   4],
           │    │     │         │                   [128, 128, 128,  ...,   3,   4,   4],
           │    │     │         │                   [132, 13...
           │    │     │         └ ()
           │    │     └ ('depths', 'positions', 'sparse_descriptors', 'probability', 'normalized_descriptors')
           │    └ <silk.flow.Flow object at 0x7f9bb6f1f070>
           └ SJNet(
               (model): DepthPro(
                 (encoder): DepthProEncoder(
                   (patch_encoder): VisionTransformer(
                     (patch_embed): ...

  File "/root/silk/silk/flow.py", line 244, in flow
    return self.flow_from_tape(tape, output_indexes, inputs)
           │    │              │     │               └ {'images': tensor([[[[126, 126, 126,  ...,   4,   4,   4],
           │    │              │     │                           [128, 128, 128,  ...,   3,   4,   4],
           │    │              │     │                           [132, 13...
           │    │              │     └ (5, 12, 17, 8, 14)
           │    │              └ ((0, ()), (1, ()), (2, [0]), (3, [1]), (4, [3, 2]), (5, ()), (6, ()), (7, [4]), (8, [6]), (9, ()), (10, [9]), (11, [10]), (12...
           │    └ <function Flow.flow_from_tape at 0x7f9bbf719990>
           └ <silk.flow.Flow object at 0x7f9bb6f1f070>

  File "/root/silk/silk/flow.py", line 221, in flow_from_tape
    session[index] = self._transitions[index](session, inputs)
    │       │        │    │            │      │        └ {'images': tensor([[[[126, 126, 126,  ...,   4,   4,   4],
    │       │        │    │            │      │                    [128, 128, 128,  ...,   3,   4,   4],
    │       │        │    │            │      │                    [132, 13...
    │       │        │    │            │      └ [None, None, None, None, None, tensor([[[[1.0000e+04, 1.0000e+04, 1.0000e+04,  ..., 1.3542e+01,
    │       │        │    │            │                   1.3875e+01, 1.3290...
    │       │        │    │            └ 10
    │       │        │    └ [<silk.flow._InputExtraction object at 0x7f9bb5cd91e0>, <silk.flow._InputExtraction object at 0x7f9bb5cd97b0>, <silk.flow._Fu...
    │       │        └ <silk.flow.Flow object at 0x7f9bb6f1f070>
    │       └ 10
    └ [None, None, None, None, None, tensor([[[[1.0000e+04, 1.0000e+04, 1.0000e+04,  ..., 1.3542e+01,
                 1.3875e+01, 1.3290...

  File "/root/silk/silk/flow.py", line 97, in __call__
    return self._function(*arguments.args, **arguments.kwargs)
           │    │          │         │       │         └ <property object at 0x7f9e0a094450>
           │    │          │         │       └ <BoundArguments (prob_map=tensor([[[[0.7979, 0.8346, 0.8416,  ..., 0.8244, 0.8168, 0.7930],
           │    │          │         │                   [0.7964, 0.8346, 0.8434...
           │    │          │         └ <property object at 0x7f9e0a094400>
           │    │          └ <BoundArguments (prob_map=tensor([[[[0.7979, 0.8346, 0.8416,  ..., 0.8244, 0.8168, 0.7930],
           │    │                      [0.7964, 0.8346, 0.8434...
           │    └ functools.partial(<function prob_map_to_points_map at 0x7f9bc3a31cf0>, prob_thresh=0.0, nms_dist=0, border_dist=8, top_k=3000)
           └ <silk.flow._FunctionCall object at 0x7f9ba57374c0>

  File "/root/silk/silk/backbones/superpoint/utils.py", line 135, in prob_map_to_points_map
    prob_thresh = torch.tensor(prob_thresh, device=prob_map.device)
                  │     │      │                   │        └ <attribute 'device' of 'torch._C.TensorBase' objects>
                  │     │      │                   └ tensor([[[0.7979, 0.8346, 0.8416,  ..., 0.8244, 0.8168, 0.7930],
                  │     │      │                              [0.7964, 0.8346, 0.8434,  ..., 0.8326, 0.8262, 0.80...
                  │     │      └ 0.0
                  │     └ <built-in method tensor of type object at 0x7f9e06c59840>
                  └ <module 'torch' from '/usr/local/lib/python3.10/dist-packages/torch/__init__.py'>

KeyboardInterrupt


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
           │         └ <code object <module> at 0x7f9e098dee40, file "/root/silk/silk/cli/__main__.py", line 1>
           └ <function _run_code at 0x7f9e0a39af80>
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'silk.cli', '__loader__': <_frozen_importlib_external.SourceFileLoad...
         └ <code object <module> at 0x7f9e098dee40, file "/root/silk/silk/cli/__main__.py", line 1>

  File "/root/silk/silk/cli/__main__.py", line 24, in <module>
    main()
    └ <function main at 0x7f9e08faa440>

  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
    └ <function _run_hydra at 0x7f9e0991dd80>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
    └ <function _run_app at 0x7f9e0991de10>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
    └ <function run_and_report at 0x7f9e0991dcf0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           └ <function _run_app.<locals>.<lambda> at 0x7f9e08e22440>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            │     └ <function Hydra.run at 0x7f9e098672e0>
            └ <hydra._internal.hydra.Hydra object at 0x7f9e09031930>
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          └ <function run_job at 0x7f9e0991cee0>
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
    │   │              │             └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │   │              └ <function main at 0x7f9e08faa3b0>
    │   └ <property object at 0x7f9e09e45f30>
    └ JobReturn(overrides=['mode=train-silk'], cfg={'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'pytho...

  File "/root/silk/silk/cli/__main__.py", line 21, in main
    silk.cli.main(cfg)
    │    │   │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
    │    │   └ <function main at 0x7f9e08fa9750>
    │    └ <module 'silk.cli' from '/root/silk/silk/cli/__init__.py'>
    └ <module 'silk' from '/root/silk/silk/__init__.py'>

> File "/root/silk/silk/cli/__init__.py", line 111, in main
    return _main(cfg, working_dir)
           │     │    └ '.'
           │     └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           └ <function _main at 0x7f9e08fa96c0>

  File "/root/silk/silk/cli/__init__.py", line 94, in _main
    output = _main_dispatch(cfg.mode.command, cfg)
             │              │                 └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             │              └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
             └ <function _main_dispatch at 0x7f9e0a201bd0>

  File "/root/silk/silk/cli/__init__.py", line 69, in _main_dispatch
    return module.main(cfg) #HERE GO SILK.CLI.TRAINING
           │      │    └ {'formatter': {'_target_': 'silk.config.formatter.get_formatter', 'name': 'python'}, 'logger': {'handlers': {'stderr-dev': {'...
           │      └ <function main at 0x7f9e08e22a70>
           └ <module 'silk.cli.training' from '/root/silk/silk/cli/training.py'>

  File "/root/silk/silk/cli/training.py", line 104, in main
    trainer.fit(model, train_loader, val_loader) #usually this becomes train
    │       │   │      │             └ <torch.utils.data.dataloader.DataLoader object at 0x7f9bb5823250>
    │       │   │      └ <torch.utils.data.dataloader.DataLoader object at 0x7f9ba5723d90>
    │       │   └ SiLKRandomHomographies(
    │       │       (model): SJNet(
    │       │         (model): DepthPro(
    │       │           (encoder): DepthProEncoder(
    │       │             (patch_encoder): V...
    │       └ <function Trainer.fit at 0x7f9bcf043a30>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>

  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 737, in fit
    self._call_and_handle_interrupt(
    │    └ <function Trainer._call_and_handle_interrupt at 0x7f9bcf043910>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 682, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           │           │       └ {}
           │           └ (SiLKRandomHomographies(
           │               (model): SJNet(
           │                 (model): DepthPro(
           │                   (encoder): DepthProEncoder(
           │                     (patch_encoder): ...
           └ <bound method Trainer._fit_impl of <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 772, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
    │    │    │                └ None
    │    │    └ SiLKRandomHomographies(
    │    │        (model): SJNet(
    │    │          (model): DepthPro(
    │    │            (encoder): DepthProEncoder(
    │    │              (patch_encoder): V...
    │    └ <function Trainer._run at 0x7f9bcf05c430>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1195, in _run
    self._dispatch()
    │    └ <function Trainer._dispatch at 0x7f9bcf05c670>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1274, in _dispatch
    self.training_type_plugin.start_training(self)
    │    │                                   └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
    │    └ <property object at 0x7f9bcf051300>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 202, in start_training
    self._results = trainer.run_stage()
    │    │          │       └ <function Trainer.run_stage at 0x7f9bcf05c700>
    │    │          └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
    │    └ None
    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9ba575ab90>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1284, in run_stage
    return self._run_train()
           │    └ <function Trainer._run_train at 0x7f9bcf05c820>
           └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py", line 1314, in _run_train
    self.fit_loop.run()
    │    └ <property object at 0x7f9bcf052d90>
    └ <pytorch_lightning.trainer.trainer.Trainer object at 0x7f9ba575b250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ ()
    │    └ <function FitLoop.advance at 0x7f9bceff6d40>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f9ba575ab00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py", line 234, in advance
    self.epoch_loop.run(data_fetcher)
    │    │          │   └ <pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f9ba5722950>
    │    │          └ <function Loop.run at 0x7f9bcf17eb90>
    │    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f9ba575a5f0>
    └ <pytorch_lightning.loops.fit_loop.FitLoop object at 0x7f9ba575ab00>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (<pytorch_lightning.utilities.fetching.DataFetcher object at 0x7f9ba5722950>,)
    │    └ <function TrainingEpochLoop.advance at 0x7f9bcefdfb50>
    └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f9ba575a5f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 195, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
                   │    │          │   │      └ 83
                   │    │          │   └ NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
                   │    │          │                [127., 127., 127.,  ...,   2.,   2....
                   │    │          └ <function Loop.run at 0x7f9bcf17eb90>
                   │    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f9ba5758fd0>
                   └ <pytorch_lightning.loops.epoch.training_epoch_loop.TrainingEpochLoop object at 0x7f9ba575a5f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
    │    │                     [127., 127., 127.,  ...,   2.,   2...
    │    └ <function TrainingBatchLoop.advance at 0x7f9bcefdc8b0>
    └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f9ba5758fd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
              │    │              │   │            │           └ 83
              │    │              │   │            └ [(0, Adam (
              │    │              │   │              Parameter Group 0
              │    │              │   │                  amsgrad: False
              │    │              │   │                  betas: [0.9, 0.999]
              │    │              │   │                  capturable: False
              │    │              │   │                  differentiable: False
              │    │              │   │                  ...
              │    │              │   └ NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
              │    │              │                [127., 127., 127.,  ...,   2.,   2....
              │    │              └ <function Loop.run at 0x7f9bcf17eb90>
              │    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9ba575b430>
              └ <pytorch_lightning.loops.batch.training_batch_loop.TrainingBatchLoop object at 0x7f9ba5758fd0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
    │    │        │       └ {}
    │    │        └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
    │    │                     [127., 127., 127.,  ...,   2.,   2...
    │    └ <function OptimizerLoop.advance at 0x7f9bcefdc160>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9ba575b430>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 215, in advance
    result = self._run_optimization(
             │    └ <function OptimizerLoop._run_optimization at 0x7f9bcefdc280>
             └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9ba575b430>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 266, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
    │    │               │          │        │          └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
    │    │               │          │        └ 83
    │    │               │          └ 0
    │    │               └ Adam (
    │    │                 Parameter Group 0
    │    │                     amsgrad: False
    │    │                     betas: [0.9, 0.999]
    │    │                     capturable: False
    │    │                     differentiable: False
    │    │                     eps: ...
    │    └ <function OptimizerLoop._optimizer_step at 0x7f9bcefdc670>
    └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9ba575b430>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 378, in _optimizer_step
    lightning_module.optimizer_step(
    │                └ <function LightningModule.optimizer_step at 0x7f9bcf062320>
    └ SiLKRandomHomographies(
        (model): SJNet(
          (model): DepthPro(
            (encoder): DepthProEncoder(
              (patch_encoder): V...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py", line 1664, in optimizer_step
    optimizer.step(closure=optimizer_closure)
    │         │            └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
    │         └ <function LightningOptimizer.step at 0x7f9c1217e7a0>
    └ LightningAdam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
      ...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py", line 164, in step
    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
    │                                  │    │           │    │               │          └ {}
    │                                  │    │           │    │               └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
    │                                  │    │           │    └ 0
    │                                  │    │           └ LightningAdam (
    │                                  │    │             Parameter Group 0
    │                                  │    │                 amsgrad: False
    │                                  │    │                 betas: [0.9, 0.999]
    │                                  │    │                 capturable: False
    │                                  │    │                 differentiable: False
    │                                  │    │             ...
    │                                  │    └ Adam (
    │                                  │      Parameter Group 0
    │                                  │          amsgrad: False
    │                                  │          betas: [0.9, 0.999]
    │                                  │          capturable: False
    │                                  │          differentiable: False
    │                                  │          eps: ...
    │                                  └ LightningAdam (
    │                                    Parameter Group 0
    │                                        amsgrad: False
    │                                        betas: [0.9, 0.999]
    │                                        capturable: False
    │                                        differentiable: False
    │                                    ...
    └ <weakproxy at 0x7f9ba56f4090 to Trainer at 0x7f9ba575b250>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 336, in optimizer_step
    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
    │    │                │              │      │          │        │          └ {}
    │    │                │              │      │          │        └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
    │    │                │              │      │          └ 0
    │    │                │              │      └ Adam (
    │    │                │              │        Parameter Group 0
    │    │                │              │            amsgrad: False
    │    │                │              │            betas: [0.9, 0.999]
    │    │                │              │            capturable: False
    │    │                │              │            differentiable: False
    │    │                │              │            eps: ...
    │    │                │              └ SiLKRandomHomographies(
    │    │                │                  (model): SJNet(
    │    │                │                    (model): DepthPro(
    │    │                │                      (encoder): DepthProEncoder(
    │    │                │                        (patch_encoder): V...
    │    │                └ <function PrecisionPlugin.optimizer_step at 0x7f9cb74e8790>
    │    └ <pytorch_lightning.plugins.precision.precision_plugin.PrecisionPlugin object at 0x7f9ba575abc0>
    └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f9ba5759810>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 163, in optimizer_step
    optimizer.step(closure=closure, **kwargs)
    │         │            │          └ {}
    │         │            └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
    │         └ <function Adam.step at 0x7f9bb5831360>
    └ Adam (
      Parameter Group 0
          amsgrad: False
          betas: [0.9, 0.999]
          capturable: False
          differentiable: False
          eps: ...
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          │     │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │     └ (Adam (
          │       Parameter Group 0
          │           amsgrad: False
          │           betas: [0.9, 0.999]
          │           capturable: False
          │           differentiable: False
          │           eps:...
          └ <function Adam.step at 0x7f9cb7e4beb0>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          │    │      │       └ {'closure': functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_p...
          │    │      └ ()
          │    └ Adam (
          │      Parameter Group 0
          │          amsgrad: False
          │          betas: [0.9, 0.999]
          │          capturable: False
          │          differentiable: False
          │          eps: ...
          └ <function Adam.step at 0x7f9cb7e4be20>
  File "/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
           └ functools.partial(<bound method PrecisionPlugin._wrap_closure of <pytorch_lightning.plugins.precision.precision_plugin.Precis...
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 148, in _wrap_closure
    closure_result = closure()
                     └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 160, in __call__
    self._result = self.closure(*args, **kwargs)
    │    │         │    │        │       └ {}
    │    │         │    │        └ ()
    │    │         │    └ <function Closure.closure at 0x7f9bcefcfbe0>
    │    │         └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
    │    └ None
    └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 142, in closure
    step_output = self._step_fn()
                  │    └ functools.partial(<bound method OptimizerLoop._training_step of <pytorch_lightning.loops.optimization.optimizer_loop.Optimize...
                  └ <pytorch_lightning.loops.optimization.optimizer_loop.Closure object at 0x7f9d24e9a2f0>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 435, in _training_step
    training_step_output = self.trainer.accelerator.training_step(step_kwargs)
                           │    │                                 └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
                           │    │                                              [127., 127.,...
                           │    └ <property object at 0x7f9bcf178310>
                           └ <pytorch_lightning.loops.optimization.optimizer_loop.OptimizerLoop object at 0x7f9ba575b430>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/accelerator.py", line 216, in training_step
    return self.training_type_plugin.training_step(*step_kwargs.values())
           │    │                    │              │           └ <method 'values' of 'collections.OrderedDict' objects>
           │    │                    │              └ OrderedDict([('batch', NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │    │                    │                           [127., 127.,...
           │    │                    └ <function DDPPlugin.training_step at 0x7f9c12209b40>
           │    └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9ba575ab90>
           └ <pytorch_lightning.accelerators.gpu.GPUAccelerator object at 0x7f9ba5759810>
  File "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py", line 439, in training_step
    return self.model(*args, **kwargs)
           │    │      │       └ {}
           │    │      └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │    │                   [127., 127., 127.,  ...,   2.,   2...
           │    └ <property object at 0x7f9c121ef240>
           └ <pytorch_lightning.plugins.training_type.ddp.DDPPlugin object at 0x7f9ba575ab90>
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           │    │           │       └ {}
           │    │           └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │    │                        [127., 127., 127.,  ...,   2.,   2...
           │    └ <function Module._call_impl at 0x7f9cb81cc700>
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           │             │       └ {}
           │             └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │                          [127., 127., 127.,  ...,   2.,   2...
           └ <bound method DistributedDataParallel.forward of DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         │    │                 │         └ {}
         │    │                 └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
         │    │                              [127., 127., 127.,  ...,   2.,   2...
         │    └ <function DistributedDataParallel._run_ddp_forward at 0x7f9cb7e103a0>
         └ DistributedDataParallel(
             (module): LightningDistributedModule(
               (module): SiLKRandomHomographies(
                 (model): SJNet(
           ...
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           │            │         └ {}
           │            └ (NamedContext({'images': tensor([[[[[126., 125., 125.,  ...,   7.,   6.,   5.],
           │                         [127., 127., 127.,  ...,   2.,   2...
           └ DistributedDataParallel(
               (module): LightningDistributedModule(
                 (module): SiLKRandomHomographies(
                   (model): SJNet(
             ...
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
    └ <built-in function _error_if_any_worker_fails>

RuntimeError: DataLoader worker (pid 64675) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
2025-02-05 12:23:53.083 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:23:56.625 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:23:56.626 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:24:00.173 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:24:23.016 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:27:35.440 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:27:35.441 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:27:39.011 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:28:01.799 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:28:33.754 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:28:33.755 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:28:37.272 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:29:00.157 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:31:50.802 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:31:50.803 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:31:54.320 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:32:28.404 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:34:41.288 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:34:41.289 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:34:44.801 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:35:07.516 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:38:18.021 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:38:18.022 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:38:21.529 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:38:44.620 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
2025-02-05 12:39:51.109 | INFO     | silk.cli:_main:87 - run CLI in mode.command=training
2025-02-05 12:39:51.110 | SUCCESS  | silk.cli:_main:91 - formatter `python` successfully instantiated
2025-02-05 12:39:54.617 | SUCCESS  | silk.cli:_main_dispatch:68 - module `silk.cli.training` successfully imported
2025-02-05 12:40:17.643 | ERROR    | silk.cli:main:113 - run failed, `*.log` file might be found in : .
